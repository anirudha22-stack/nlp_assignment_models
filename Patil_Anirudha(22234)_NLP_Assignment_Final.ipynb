{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "L_jOA4yC48Nn"
      },
      "id": "L_jOA4yC48Nn"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "84b8b960-7711-444c-aa5d-78af50b86006",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84b8b960-7711-444c-aa5d-78af50b86006",
        "outputId": "d6fad47f-62ca-48cb-861d-5a81f5c3f6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41157 entries, 0 to 41156\n",
            "Data columns (total 6 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   UserName       41157 non-null  int64 \n",
            " 1   ScreenName     41157 non-null  int64 \n",
            " 2   Location       32567 non-null  object\n",
            " 3   TweetAt        41157 non-null  object\n",
            " 4   OriginalTweet  41157 non-null  object\n",
            " 5   Sentiment      41157 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 1.9+ MB\n",
            "\n",
            "--- Sample Training Data ---\n",
            "   UserName  ScreenName   Location     TweetAt  \\\n",
            "0      3799       48751     London  16-03-2020   \n",
            "1      3800       48752         UK  16-03-2020   \n",
            "2      3801       48753  Vagabonds  16-03-2020   \n",
            "3      3802       48754        NaN  16-03-2020   \n",
            "4      3803       48755        NaN  16-03-2020   \n",
            "\n",
            "                                       OriginalTweet           Sentiment  \n",
            "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
            "1  advice Talk to your neighbours family to excha...            Positive  \n",
            "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
            "3  My food stock is not the only one which is emp...            Positive  \n",
            "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
            "\n",
            "Training data shape: (41157, 6)\n",
            "Test data shape: (3798, 6)\n",
            "\n",
            "Sentiment distribution in training data:\n",
            "Sentiment\n",
            "Positive              11422\n",
            "Negative               9917\n",
            "Neutral                7713\n",
            "Extremely Positive     6624\n",
            "Extremely Negative     5481\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle # To save vocabulary\n",
        "from collections import Counter\n",
        "\n",
        "# --- Load Data ---\n",
        "# URLs for the raw CSV files on GitHub\n",
        "train_url = 'https://raw.githubusercontent.com/islnlp/Advance-NLP-assingment-/main/Corona_NLP_train.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/islnlp/Advance-NLP-assingment-/main/Corona_NLP_test.csv'\n",
        "\n",
        "# It's good practice to specify encoding\n",
        "df_train = pd.read_csv(train_url, encoding='latin1')\n",
        "df_test = pd.read_csv(test_url, encoding='latin1')\n",
        "\n",
        "print(\"--- Training Data Info ---\")\n",
        "df_train.info()\n",
        "print(\"\\n--- Sample Training Data ---\")\n",
        "print(df_train.head())\n",
        "\n",
        "# --- Basic Exploration ---\n",
        "print(f\"\\nTraining data shape: {df_train.shape}\")\n",
        "print(f\"Test data shape: {df_test.shape}\")\n",
        "print(f\"\\nSentiment distribution in training data:\\n{df_train['Sentiment'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "94b89832-b617-48e1-95f7-55ccd9ae67cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b89832-b617-48e1-95f7-55ccd9ae67cd",
        "outputId": "65a10c04-6165-4fb3-8f24-2dc7c3d0d7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available Classes: ['Neutral' 'Positive' 'Extremely Negative' 'Negative' 'Extremely Positive']\n"
          ]
        }
      ],
      "source": [
        "# List of unique classes\n",
        "classes = df_train['Sentiment'].unique()\n",
        "print(\"Available Classes:\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "209fca77-69a0-4d12-a41e-b5e596d3896e",
      "metadata": {
        "id": "209fca77-69a0-4d12-a41e-b5e596d3896e"
      },
      "source": [
        "## Part 1. Data Preprocessing Step"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3010b981-f7f3-47a9-b897-f202b4bc2f2c",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "3010b981-f7f3-47a9-b897-f202b4bc2f2c"
      },
      "source": [
        "### 1. Text Cleaning and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "81043cc6-9169-4451-bd36-dabfe3e91917",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81043cc6-9169-4451-bd36-dabfe3e91917",
        "outputId": "f3fc3564-ae3d-4914-a2de-33b83ef5129a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Processed Tokens ---\n",
            "                                       OriginalTweet  \\\n",
            "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
            "1  advice Talk to your neighbours family to excha...   \n",
            "2  Coronavirus Australia: Woolworths to give elde...   \n",
            "3  My food stock is not the only one which is emp...   \n",
            "4  Me, ready to go at supermarket during the #COV...   \n",
            "\n",
            "                                              tokens  \n",
            "0                                         [and, and]  \n",
            "1  [advice, talk, to, your, neighbours, family, t...  \n",
            "2  [coronavirus, australia, woolworths, to, give,...  \n",
            "3  [my, food, stock, is, not, the, only, one, whi...  \n",
            "4  [me, ready, to, go, at, supermarket, during, t...  \n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and tokenizes a single text string.\n",
        "    \"\"\"\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    # Remove Twitter handles\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove non-alphanumeric characters (keep spaces)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize by splitting on whitespace\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Apply preprocessing to the tweet column\n",
        "df_train['tokens'] = df_train['OriginalTweet'].apply(preprocess_text)\n",
        "df_test['tokens'] = df_test['OriginalTweet'].apply(preprocess_text)\n",
        "\n",
        "print(\"\\n--- Sample Processed Tokens ---\")\n",
        "print(df_train[['OriginalTweet', 'tokens']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ab1847bd-63f9-428e-b1c9-92432dbda0ee",
      "metadata": {
        "id": "ab1847bd-63f9-428e-b1c9-92432dbda0ee"
      },
      "outputs": [],
      "source": [
        "# Calculate the length of each token list\n",
        "df_train['token_len'] = df_train['tokens'].apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b5b18cc7-94b7-4684-af96-f877ea01ba1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5b18cc7-94b7-4684-af96-f877ea01ba1b",
        "outputId": "ac8cf839-9934-4c42-e947-7620d0bb9c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Analysis of Tweet Lengths ---\n",
            "count    41157.000000\n",
            "mean        28.770051\n",
            "std         11.526695\n",
            "min          0.000000\n",
            "50%         30.000000\n",
            "90%         43.000000\n",
            "95%         46.000000\n",
            "98%         49.000000\n",
            "99%         51.000000\n",
            "max         62.000000\n",
            "Name: token_len, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Analyze the distribution of token lengths\n",
        "print(\"\\n--- Analysis of Tweet Lengths ---\")\n",
        "print(df_train['token_len'].describe(percentiles=[0.90, 0.95, 0.98, 0.99]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b90af21-b137-4923-b89d-c652f93d26f9",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "0b90af21-b137-4923-b89d-c652f93d26f9"
      },
      "source": [
        "### 2. Vocabulary Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "48460559-7b78-431e-b9a1-fe8424f5b6c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48460559-7b78-431e-b9a1-fe8424f5b6c6",
        "outputId": "e7c0b468-4d1f-4aad-e840-9644acdd815b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary size: 10000\n"
          ]
        }
      ],
      "source": [
        "def build_vocab(token_lists, max_vocab_size=10000):\n",
        "    \"\"\"\n",
        "    Builds a vocabulary from a list of token lists.\n",
        "    \"\"\"\n",
        "    # Count word frequencies\n",
        "    word_counts = Counter(word for tokens in token_lists for word in tokens)\n",
        "\n",
        "    # Get the most common words\n",
        "    most_common_words = word_counts.most_common(max_vocab_size - 2) # Reserve space for padding and unknown\n",
        "\n",
        "    # Create word-to-index mapping\n",
        "    # <PAD>: Padding token, index 0\n",
        "    # <UNK>: Unknown word token, index 1\n",
        "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for i, (word, _) in enumerate(most_common_words):\n",
        "        word_to_idx[word] = i + 2\n",
        "\n",
        "    return word_to_idx\n",
        "\n",
        "# Build vocabulary from the training data\n",
        "vocab = build_vocab(df_train['tokens'])\n",
        "print(f\"\\nVocabulary size: {len(vocab)}\")\n",
        "\n",
        "# Save the vocabulary for later use\n",
        "with open('vocab.pkl', 'wb') as f:\n",
        "    pickle.dump(vocab, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8239030a-9260-4d35-91dc-d7029394de49",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8239030a-9260-4d35-91dc-d7029394de49"
      },
      "source": [
        "### 3. Text Encoding and Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e258c4ac-fe92-4093-ba4d-2cdd1893e652",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e258c4ac-fe92-4093-ba4d-2cdd1893e652",
        "outputId": "16c640d6-7956-47be-acd2-a1b074b30f34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample Encoded and Padded Sequence ---\n",
            "Original Tokens: ['and', 'and']\n",
            "Encoded Sequence: [4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "def encode_and_pad(tokens, word_to_idx, max_len=60):\n",
        "    \"\"\"\n",
        "    Encodes tokens to indices and pads/truncates the sequence.\n",
        "    \"\"\"\n",
        "    # Encode tokens to indices, using <UNK> for out-of-vocab words\n",
        "    encoded = [word_to_idx.get(token, word_to_idx['<UNK>']) for token in tokens]\n",
        "\n",
        "    # Pad or truncate\n",
        "    if len(encoded) < max_len:\n",
        "        # Pad with <PAD> token (index 0)\n",
        "        encoded += [word_to_idx['<PAD>']] * (max_len - len(encoded))\n",
        "    else:\n",
        "        # Truncate\n",
        "        encoded = encoded[:max_len]\n",
        "\n",
        "    return encoded\n",
        "\n",
        "# Define a fixed sequence length\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "\n",
        "# Apply encoding and padding\n",
        "df_train['encoded'] = df_train['tokens'].apply(lambda x: encode_and_pad(x, vocab, MAX_SEQUENCE_LENGTH))\n",
        "df_test['encoded'] = df_test['tokens'].apply(lambda x: encode_and_pad(x, vocab, MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "print(\"\\n--- Sample Encoded and Padded Sequence ---\")\n",
        "print(f\"Original Tokens: {df_train['tokens'].iloc[0]}\")\n",
        "print(f\"Encoded Sequence: {df_train['encoded'].iloc[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9f14c57-5552-4bbf-89b4-b63bc7fe9944",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "d9f14c57-5552-4bbf-89b4-b63bc7fe9944"
      },
      "source": [
        "### 4. Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7d4e7f99-c23f-4007-a58b-ba981b472138",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d4e7f99-c23f-4007-a58b-ba981b472138",
        "outputId": "bf6c03bf-abb1-4046-fed3-9ee6430a08e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Label Mapping ---\n",
            "{'Extremely Negative': 0, 'Negative': 1, 'Neutral': 2, 'Positive': 3, 'Extremely Positive': 4}\n"
          ]
        }
      ],
      "source": [
        "# Create a mapping from sentiment to integer\n",
        "label_map = {\n",
        "    'Extremely Negative': 0,\n",
        "    'Negative': 1,\n",
        "    'Neutral': 2,\n",
        "    'Positive': 3,\n",
        "    'Extremely Positive': 4\n",
        "}\n",
        "# And the reverse mapping for interpretation later\n",
        "idx_to_label = {v: k for k, v in label_map.items()}\n",
        "\n",
        "df_train['label'] = df_train['Sentiment'].map(label_map)\n",
        "df_test['label'] = df_test['Sentiment'].map(label_map)\n",
        "\n",
        "print(\"\\n--- Label Mapping ---\")\n",
        "print(label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22c91914-5ddd-479e-bfc2-c393ed9d8143",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "22c91914-5ddd-479e-bfc2-c393ed9d8143"
      },
      "source": [
        "### 5. Final Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4f866d29-f612-45e1-ac03-6b988d719a9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f866d29-f612-45e1-ac03-6b988d719a9d",
        "outputId": "db643e5c-662a-468a-8b03-d3c06d323024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final training data shape: X_train=(41157, 50), y_train=(41157,)\n",
            "Final testing data shape: X_test=(3798, 50), y_test=(3798,)\n"
          ]
        }
      ],
      "source": [
        "# Convert final data into NumPy arrays\n",
        "X_train = np.array(df_train['encoded'].tolist())\n",
        "y_train = np.array(df_train['label'].tolist())\n",
        "\n",
        "X_test = np.array(df_test['encoded'].tolist())\n",
        "y_test = np.array(df_test['label'].tolist())\n",
        "\n",
        "print(f\"\\nFinal training data shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Final testing data shape: X_test={X_test.shape}, y_test={y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96a9605-14ad-489e-9864-faf2ea50de78",
      "metadata": {
        "id": "b96a9605-14ad-489e-9864-faf2ea50de78"
      },
      "source": [
        "## Part 2. Building Essentials for Model (Layers, Activationn Optimizers, Loss Function)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e381588-b1d1-47ae-ba5d-d5481b1c71e5",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "8e381588-b1d1-47ae-ba5d-d5481b1c71e5"
      },
      "source": [
        "### 1. Base Layer and Activation Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c21f3722-6e74-4b00-a483-118b8ab92546",
      "metadata": {
        "id": "c21f3722-6e74-4b00-a483-118b8ab92546"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    \"\"\"Base class for all layers.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.params = {} # For weights and biases\n",
        "        self.grads = {}  # For gradients\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, grad):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Tanh:\n",
        "    \"\"\"Tanh activation function.\"\"\"\n",
        "    def forward(self, x):\n",
        "        self.y = np.tanh(x)\n",
        "        return self.y\n",
        "\n",
        "    def backward(self, grad):\n",
        "        return grad * (1 - self.y**2)\n",
        "\n",
        "class Sigmoid:\n",
        "    \"\"\"Sigmoid activation function.\"\"\"\n",
        "    def forward(self, x):\n",
        "        self.y = 1 / (1 + np.exp(-x))\n",
        "        return self.y\n",
        "\n",
        "    def backward(self, grad):\n",
        "        return grad * self.y * (1 - self.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "912cd981-1566-4e9b-9092-d77eb8d8af69",
      "metadata": {
        "id": "912cd981-1566-4e9b-9092-d77eb8d8af69"
      },
      "source": [
        "### 2. Core Network Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044c0b87-3f5f-42e1-a2fc-c24607855a3b",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "044c0b87-3f5f-42e1-a2fc-c24607855a3b"
      },
      "source": [
        "#### Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "44ff3f71-e9a2-4362-83d5-cafc7b3d19af",
      "metadata": {
        "id": "44ff3f71-e9a2-4362-83d5-cafc7b3d19af"
      },
      "outputs": [],
      "source": [
        "class Embedding(Layer):\n",
        "    \"\"\"\n",
        "    Embedding layer: turns positive integers (indexes) into dense vectors of fixed size.\n",
        "    e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "        # Xavier Glorot initialization\n",
        "        limit = np.sqrt(6 / (vocab_size + embed_dim))\n",
        "        self.params['W'] = np.random.uniform(-limit, limit, (vocab_size, embed_dim))\n",
        "        self.grads['W'] = np.zeros_like(self.params['W'])\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Inputs shape: (batch_size, seq_len)\n",
        "        Output shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        self.inputs = inputs\n",
        "        return self.params['W'][inputs]\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Gradient shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        # The gradient of the embedding matrix W is the sum of the gradients\n",
        "        # for each word that appeared in the input.\n",
        "        # Np.add.at is used for efficient in-place addition at specific indices.\n",
        "        np.add.at(self.grads['W'], self.inputs, grad)\n",
        "        return None # This is the first layer, so no gradient to pass back"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221ef1bb-2935-4816-a22f-8a390498a47e",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "221ef1bb-2935-4816-a22f-8a390498a47e"
      },
      "source": [
        "#### Dense (Fully-Connected) Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ddc5a4f2-e31a-4ff6-8f39-93759f765aad",
      "metadata": {
        "id": "ddc5a4f2-e31a-4ff6-8f39-93759f765aad"
      },
      "outputs": [],
      "source": [
        "class Dense(Layer):\n",
        "    \"\"\"\n",
        "    A fully-connected layer.\n",
        "    Updated to handle both 2D and 3D input tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        # Xavier Glorot initialization\n",
        "        limit = np.sqrt(6 / (input_size + output_size))\n",
        "        self.params['W'] = np.random.uniform(-limit, limit, (input_size, output_size))\n",
        "        self.params['b'] = np.zeros(output_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Inputs shape: (batch_size, ..., input_size)\n",
        "        Output shape: (batch_size, ..., output_size)\n",
        "        \"\"\"\n",
        "        self.inputs = inputs\n",
        "        return inputs @ self.params['W'] + self.params['b']\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        grad shape: (batch_size, ..., output_size)\n",
        "        Handles both 2D and 3D cases for Transformer compatibility.\n",
        "        \"\"\"\n",
        "        # For the bias gradient, sum over all dimensions except the last one (features).\n",
        "        sum_axes = tuple(range(grad.ndim - 1))\n",
        "        self.grads['b'] = np.sum(grad, axis=sum_axes)\n",
        "\n",
        "        # For the weight gradient, we need (D_in, N) @ (N, D_out)\n",
        "        # If input is 3D (N, S, D_in), we reshape to (N*S, D_in)\n",
        "        if self.inputs.ndim == 3:\n",
        "            N, S, D_in = self.inputs.shape\n",
        "            D_out = grad.shape[-1]\n",
        "            # Reshape inputs and grad to be 2D for the matmul\n",
        "            inputs_reshaped = self.inputs.reshape(N * S, D_in)\n",
        "            grad_reshaped = grad.reshape(N * S, D_out)\n",
        "            self.grads['W'] = inputs_reshaped.T @ grad_reshaped\n",
        "        else: # Original 2D case for RNN/LSTM and the final Dense layer in Transformer\n",
        "            self.grads['W'] = self.inputs.T @ grad\n",
        "\n",
        "        # The gradient w.r.t input is still a simple matmul\n",
        "        return grad @ self.params['W'].T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009f0af5-3a87-4069-9178-7d7e86cc731d",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "009f0af5-3a87-4069-9178-7d7e86cc731d"
      },
      "source": [
        "#### 3. Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3f2f35bc-75b8-43ec-a4ab-c7018a079c17",
      "metadata": {
        "id": "3f2f35bc-75b8-43ec-a4ab-c7018a079c17"
      },
      "outputs": [],
      "source": [
        "class SoftmaxCrossEntropy:\n",
        "    \"\"\"\n",
        "    Computes the cross-entropy loss after applying softmax.\n",
        "    y_pred is expected to be logits (raw outputs from the last dense layer).\n",
        "    y_true is expected to be integer class labels.\n",
        "    \"\"\"\n",
        "    def forward(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        y_pred shape: (batch_size, num_classes)\n",
        "        y_true shape: (batch_size,)\n",
        "        \"\"\"\n",
        "        self.y_true = y_true\n",
        "        batch_size = y_pred.shape[0]\n",
        "\n",
        "        # Stabilize softmax by subtracting the max logit\n",
        "        exp_preds = np.exp(y_pred - np.max(y_pred, axis=1, keepdims=True))\n",
        "        self.probs = exp_preds / np.sum(exp_preds, axis=1, keepdims=True)\n",
        "\n",
        "        # Calculate loss\n",
        "        log_likelihood = -np.log(self.probs[range(batch_size), y_true])\n",
        "        loss = np.sum(log_likelihood) / batch_size\n",
        "        return loss\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        Calculates the gradient of the loss with respect to y_pred (the logits).\n",
        "        \"\"\"\n",
        "        batch_size = self.probs.shape[0]\n",
        "        grad = self.probs.copy()\n",
        "\n",
        "        # The gradient is simply (probs - 1) for the correct class\n",
        "        grad[range(batch_size), self.y_true] -= 1\n",
        "        grad /= batch_size\n",
        "        return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cef627c-09fe-4846-9913-d58a8be28c47",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "3cef627c-09fe-4846-9913-d58a8be28c47"
      },
      "source": [
        "#### 4. The Adam Optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cd8fb978-1d89-47de-b261-564cf4b9615e",
      "metadata": {
        "id": "cd8fb978-1d89-47de-b261-564cf4b9615e"
      },
      "outputs": [],
      "source": [
        "class Adam:\n",
        "    \"\"\"\n",
        "    The Adam optimizer with gradient clipping.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, learning_rate=0.001, beta1=0.9, beta2=0.999,\n",
        "                 epsilon=1e-8, clip_value=1.0, clip_norm=None):\n",
        "        self.layers = layers\n",
        "        self.lr = learning_rate\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.clip_value = clip_value  # Value clipping threshold\n",
        "        self.clip_norm = clip_norm    # Gradient norm clipping threshold\n",
        "        self.t = 0\n",
        "\n",
        "        # Initialize moment vectors for each parameter in each layer\n",
        "        self.m = {}\n",
        "        self.v = {}\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            # Only initialize moments for layers that have parameters\n",
        "            if hasattr(layer, 'params'):\n",
        "                for key in layer.params:\n",
        "                    param_key = f'layer_{i}_{key}'\n",
        "                    self.m[param_key] = np.zeros_like(layer.params[key])\n",
        "                    self.v[param_key] = np.zeros_like(layer.params[key])\n",
        "\n",
        "    def _clip_gradients(self, grads):\n",
        "        \"\"\"\n",
        "        Apply gradient clipping to prevent exploding gradients.\n",
        "        Supports both value clipping and norm clipping.\n",
        "        \"\"\"\n",
        "        if self.clip_value is not None:\n",
        "            # Value clipping: clip each gradient element individually\n",
        "            grads = np.clip(grads, -self.clip_value, self.clip_value)\n",
        "\n",
        "        if self.clip_norm is not None:\n",
        "            # Norm clipping: scale gradients if their norm exceeds threshold\n",
        "            grad_norm = np.linalg.norm(grads)\n",
        "            if grad_norm > self.clip_norm:\n",
        "                grads = grads * (self.clip_norm / (grad_norm + self.epsilon))\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step with gradient clipping.\n",
        "        \"\"\"\n",
        "        self.t += 1\n",
        "\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            # Only update parameters for layers that have them\n",
        "            if hasattr(layer, 'params'):\n",
        "                for key, param in layer.params.items():\n",
        "                    param_key = f'layer_{i}_{key}'\n",
        "\n",
        "                    # Ensure the layer has gradients for this parameter\n",
        "                    if key in layer.grads:\n",
        "                        grad = layer.grads[key].copy()  # Make a copy to avoid modifying original\n",
        "\n",
        "                        # Apply gradient clipping\n",
        "                        grad = self._clip_gradients(grad)\n",
        "\n",
        "                        # Update biased first moment estimate\n",
        "                        self.m[param_key] = self.beta1 * self.m[param_key] + (1 - self.beta1) * grad\n",
        "\n",
        "                        # Update biased second raw moment estimate\n",
        "                        self.v[param_key] = self.beta2 * self.v[param_key] + (1 - self.beta2) * (grad**2)\n",
        "\n",
        "                        # Compute bias-corrected first moment estimate\n",
        "                        m_hat = self.m[param_key] / (1 - self.beta1**self.t)\n",
        "\n",
        "                        # Compute bias-corrected second raw moment estimate\n",
        "                        v_hat = self.v[param_key] / (1 - self.beta2**self.t)\n",
        "\n",
        "                        # Update parameters\n",
        "                        update = self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n",
        "                        param -= update\n",
        "\n",
        "    def zero_grad(self):\n",
        "        \"\"\"\n",
        "        Reset gradients for all layers (optional but good practice)\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            if hasattr(layer, 'grads'):\n",
        "                for key in layer.grads:\n",
        "                    layer.grads[key] = np.zeros_like(layer.grads[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585e813a-b4be-4361-be0a-7ff21eb53043",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "585e813a-b4be-4361-be0a-7ff21eb53043"
      },
      "source": [
        "#### 5. Classification Report Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3b206f5d-1677-43da-b9b9-d39cfb01546a",
      "metadata": {
        "id": "3b206f5d-1677-43da-b9b9-d39cfb01546a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def classification_report_from_scratch(y_true, y_pred, class_names=None):\n",
        "    \"\"\"\n",
        "    Generates and prints a text report showing the main classification metrics.\n",
        "    Now includes micro, macro, and weighted averages for F1-score.\n",
        "    \"\"\"\n",
        "    # Get unique class labels, sorted for consistent ordering\n",
        "    unique_labels = sorted(np.unique(np.concatenate((y_true, y_pred))))\n",
        "\n",
        "    if class_names is None:\n",
        "        class_names = [f\"Class {label}\" for label in unique_labels]\n",
        "\n",
        "    max_name_len = max([len(name) for name in class_names] + [len(\"weighted avg\")])\n",
        "\n",
        "    # --- Print Header ---\n",
        "    header = (\n",
        "        f\"{'':<{max_name_len}}  \"\n",
        "        f\"{'precision':>10}  {'recall':>10}  {'f1-score':>10}  {'support':>10}\\n\\n\"\n",
        "    )\n",
        "    report_str = header\n",
        "\n",
        "    # Initialize for calculations\n",
        "    precisions, recalls, f1_scores, supports = [], [], [], []\n",
        "    total_tp, total_fp, total_fn = 0, 0, 0\n",
        "\n",
        "    # --- Calculate and format metrics for each class ---\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        true_class = (y_true == label)\n",
        "        pred_class = (y_pred == label)\n",
        "\n",
        "        tp = np.sum(true_class & pred_class)\n",
        "        fp = np.sum(~true_class & pred_class)\n",
        "        fn = np.sum(true_class & ~pred_class)\n",
        "\n",
        "        support = np.sum(true_class)\n",
        "\n",
        "        # Aggregate totals for micro-average calculation\n",
        "        total_tp += tp\n",
        "        total_fp += fp\n",
        "        total_fn += fn\n",
        "\n",
        "        epsilon = 1e-8\n",
        "        precision = tp / (tp + fp + epsilon)\n",
        "        recall = tp / (tp + fn + epsilon)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "        f1_scores.append(f1_score)\n",
        "        supports.append(support)\n",
        "\n",
        "        report_str += (\n",
        "            f\"{class_names[i]:<{max_name_len}}  \"\n",
        "            f\"{precision:>10.2f}  \"\n",
        "            f\"{recall:>10.2f}  \"\n",
        "            f\"{f1_score:>10.2f}  \"\n",
        "            f\"{support:>10}\\n\"\n",
        "        )\n",
        "\n",
        "    report_str += \"\\n\"\n",
        "    total_samples = np.sum(supports)\n",
        "\n",
        "    # --- Calculate and format overall and average metrics ---\n",
        "    accuracy = np.sum(y_true == y_pred) / total_samples\n",
        "\n",
        "    # Accuracy\n",
        "    report_str += (\n",
        "        f\"{'accuracy':<{max_name_len}}  \"\n",
        "        f\"{'':>10}  {'':>10}  \"\n",
        "        f\"{accuracy:>10.2f}  {total_samples:>10}\\n\"\n",
        "    )\n",
        "\n",
        "    # --- NEW: Micro Average Calculation ---\n",
        "    # Note: In multiclass, micro-precision, micro-recall, and micro-f1 are all equal to accuracy.\n",
        "    micro_precision = total_tp / (total_tp + total_fp + 1e-8)\n",
        "    micro_recall = total_tp / (total_tp + total_fn + 1e-8)\n",
        "    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall + 1e-8)\n",
        "    report_str += (\n",
        "        f\"{'micro avg':<{max_name_len}}  \"\n",
        "        f\"{micro_precision:>10.2f}  \"\n",
        "        f\"{micro_recall:>10.2f}  \"\n",
        "        f\"{micro_f1:>10.2f}  \"\n",
        "        f\"{total_samples:>10}\\n\"\n",
        "    )\n",
        "\n",
        "    # Macro average\n",
        "    report_str += (\n",
        "        f\"{'macro avg':<{max_name_len}}  \"\n",
        "        f\"{np.mean(precisions):>10.2f}  \"\n",
        "        f\"{np.mean(recalls):>10.2f}  \"\n",
        "        f\"{np.mean(f1_scores):>10.2f}  \"\n",
        "        f\"{total_samples:>10}\\n\"\n",
        "    )\n",
        "\n",
        "    # Weighted average\n",
        "    report_str += (\n",
        "        f\"{'weighted avg':<{max_name_len}}  \"\n",
        "        f\"{np.sum(np.array(precisions) * np.array(supports)) / total_samples:>10.2f}  \"\n",
        "        f\"{np.sum(np.array(recalls) * np.array(supports)) / total_samples:>10.2f}  \"\n",
        "        f\"{np.sum(np.array(f1_scores) * np.array(supports)) / total_samples:>10.2f}  \"\n",
        "        f\"{total_samples:>10}\\n\"\n",
        "    )\n",
        "\n",
        "    print(report_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1f9b0e9-7d08-4e3c-b1c1-ebe63b129fce",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "a1f9b0e9-7d08-4e3c-b1c1-ebe63b129fce"
      },
      "source": [
        "#### 6. Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "72b84eaa-29ff-4152-bb8f-e5ea64720fe3",
      "metadata": {
        "id": "72b84eaa-29ff-4152-bb8f-e5ea64720fe3"
      },
      "outputs": [],
      "source": [
        "class Dropout(Layer):\n",
        "    \"\"\"\n",
        "    Implements the Dropout layer for regularization.\n",
        "    \"\"\"\n",
        "    def __init__(self, p=0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        \"\"\"\n",
        "        Applies dropout during training.\n",
        "        During evaluation (training=False), it does nothing.\n",
        "        \"\"\"\n",
        "        if training:\n",
        "            # Create a mask and apply inverted dropout\n",
        "            # We scale the outputs by 1/(1-p) during training\n",
        "            self.mask = (np.random.rand(*x.shape) > self.p) / (1 - self.p)\n",
        "            return x * self.mask\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Applies the same mask to the gradients.\n",
        "        \"\"\"\n",
        "        # Gradients only flow through the neurons that were not dropped out\n",
        "        return grad * self.mask"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5ef2e80-07fc-4fcf-bc81-06b6772e8604",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "a5ef2e80-07fc-4fcf-bc81-06b6772e8604"
      },
      "source": [
        "#### 7. Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "66109727-373a-4626-a54d-673248dae636",
      "metadata": {
        "id": "66109727-373a-4626-a54d-673248dae636"
      },
      "outputs": [],
      "source": [
        "# --- Saving Weights while Training ---\n",
        "\n",
        "def save_weights(model, path):\n",
        "    \"\"\"Saves model weights to a file.\"\"\"\n",
        "    weights = {}\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        for key, param in layer.params.items():\n",
        "            weights[f'layer_{i}_{key}'] = param\n",
        "    np.savez(path, **weights)\n",
        "    print(f\"Weights saved to {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb54f7e1-2c98-4bfa-aa50-b8fed822c6a9",
      "metadata": {
        "id": "fb54f7e1-2c98-4bfa-aa50-b8fed822c6a9"
      },
      "source": [
        "## Part 3. Model 1 - RNN from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4faa6bab-b4fd-490e-8624-9a08a9e9c8a3",
      "metadata": {
        "id": "4faa6bab-b4fd-490e-8624-9a08a9e9c8a3"
      },
      "source": [
        "### 1. Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "63788a19-1a28-4a86-96ab-30e99fac2e22",
      "metadata": {
        "id": "63788a19-1a28-4a86-96ab-30e99fac2e22"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Note: The classes from Part 2 (Layer, Tanh, Embedding, Dense, etc.) are assumed to be defined.\n",
        "\n",
        "class SimpleRNN(Layer):\n",
        "    \"\"\"\n",
        "    A simple Recurrent Neural Network layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Xavier initialization\n",
        "        xavier_std = np.sqrt(2.0 / (input_size + hidden_size))\n",
        "        self.params['W_xh'] = np.random.randn(input_size, hidden_size) * xavier_std\n",
        "        self.params['W_hh'] = np.random.randn(hidden_size, hidden_size) * 0.01  # Smaller for recurrent weights\n",
        "        self.params['b_h'] = np.zeros(hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Processes a sequence of inputs.\n",
        "        Inputs shape: (batch_size, seq_len, input_size)\n",
        "        Output shape: (batch_size, hidden_size) -> The final hidden state\n",
        "        \"\"\"\n",
        "        self.inputs = inputs\n",
        "        batch_size, seq_len, _ = inputs.shape\n",
        "\n",
        "        # Initialize hidden state and storage for backprop\n",
        "        self.h_states = np.zeros((batch_size, seq_len + 1, self.hidden_size))\n",
        "        self.tanh_inputs = np.zeros((batch_size, seq_len, self.hidden_size))\n",
        "\n",
        "        # Initial hidden state h_0 is all zeros\n",
        "        h = self.h_states[:, 0, :]\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            x_t = inputs[:, t, :]\n",
        "            pre_activation = x_t @ self.params['W_xh'] + h @ self.params['W_hh'] + self.params['b_h']\n",
        "            self.tanh_inputs[:, t, :] = pre_activation\n",
        "            h = np.tanh(pre_activation)\n",
        "            self.h_states[:, t+1, :] = h\n",
        "\n",
        "        return h # Return the final hidden state\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Performs Backpropagation Through Time (BPTT).\n",
        "        grad shape: (batch_size, hidden_size) -> gradient of the final hidden state\n",
        "        Returns gradient w.r.t inputs: (batch_size, seq_len, input_size)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = self.inputs.shape\n",
        "\n",
        "        # Initialize gradients for parameters and input\n",
        "        self.grads['W_xh'] = np.zeros_like(self.params['W_xh'])\n",
        "        self.grads['W_hh'] = np.zeros_like(self.params['W_hh'])\n",
        "        self.grads['b_h'] = np.zeros_like(self.params['b_h'])\n",
        "        grad_inputs = np.zeros_like(self.inputs)\n",
        "\n",
        "        # Gradient of the hidden state, starting from the end and flowing backwards\n",
        "        grad_h_next = grad\n",
        "\n",
        "        for t in reversed(range(seq_len)):\n",
        "            # Gradient through the tanh activation\n",
        "            grad_tanh = (1 - self.h_states[:, t+1, :]**2) * grad_h_next\n",
        "\n",
        "            # Gradients for parameters at this time step\n",
        "            self.grads['b_h'] += np.sum(grad_tanh, axis=0)\n",
        "            self.grads['W_xh'] += self.inputs[:, t, :].T @ grad_tanh\n",
        "            self.grads['W_hh'] += self.h_states[:, t, :].T @ grad_tanh # Use h_{t-1}\n",
        "\n",
        "            # Gradient to pass to the previous hidden state\n",
        "            grad_h_prev = grad_tanh @ self.params['W_hh'].T\n",
        "\n",
        "            # Gradient for the input at this time step\n",
        "            grad_inputs[:, t, :] = grad_tanh @ self.params['W_xh'].T\n",
        "\n",
        "            # Update the hidden state gradient for the next iteration (t-1)\n",
        "            grad_h_next = grad_h_prev\n",
        "\n",
        "        return grad_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "668ec24e-e733-4e9c-ae59-52f75a916ec9",
      "metadata": {
        "id": "668ec24e-e733-4e9c-ae59-52f75a916ec9"
      },
      "source": [
        "### 2. Assembling the Full RNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c267e396-ce4f-4e37-8ad6-8fbf9aead7b1",
      "metadata": {
        "id": "c267e396-ce4f-4e37-8ad6-8fbf9aead7b1"
      },
      "outputs": [],
      "source": [
        "class RNNClassifier:\n",
        "    \"\"\"\n",
        "    A complete RNN model for classification.\n",
        "    (Your __init__ and other methods remain the same)\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes, dropout_p=0.3):\n",
        "        self.embedding = Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = SimpleRNN(embed_dim, hidden_size)\n",
        "        self.dropout = Dropout(dropout_p)\n",
        "        self.dense = Dense(hidden_size, num_classes)\n",
        "        self.layers = [self.embedding, self.rnn, self.dropout, self.dense]\n",
        "\n",
        "    def forward(self, inputs, training=True):\n",
        "        \"\"\"\n",
        "        Forward pass for the classifier.\n",
        "        The 'training' flag controls the dropout layer.\n",
        "        \"\"\"\n",
        "        x = self.embedding.forward(inputs)\n",
        "        x = self.rnn.forward(x)\n",
        "        # Apply dropout only during training\n",
        "        x = self.dropout.forward(x, training=training)\n",
        "        x = self.dense.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Backward pass for the classifier.\n",
        "        \"\"\"\n",
        "        grad = self.dense.backward(grad)\n",
        "        # Add the backward pass for the dropout layer\n",
        "        grad = self.dropout.backward(grad)\n",
        "        grad = self.rnn.backward(grad)\n",
        "        self.embedding.backward(grad)\n",
        "\n",
        "    def get_params(self):\n",
        "        params = []\n",
        "        for layer in self.layers:\n",
        "            params.extend(layer.params.values())\n",
        "        return params\n",
        "\n",
        "    def get_grads(self):\n",
        "        grads = []\n",
        "        for layer in self.layers:\n",
        "            grads.extend(layer.grads.values())\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6f2da7f-13ba-424f-9165-d9b53fd7bd7c",
      "metadata": {
        "id": "d6f2da7f-13ba-424f-9165-d9b53fd7bd7c"
      },
      "source": [
        "### 3. Training RNN and Weight Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1a60baba-2bd3-4137-a638-83bc14bcb897",
      "metadata": {
        "id": "1a60baba-2bd3-4137-a638-83bc14bcb897"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import requests\n",
        "# import io\n",
        "# from tqdm import tqdm # For a nice progress bar\n",
        "\n",
        "\n",
        "# # --- Model and Training Hyperparameters ---\n",
        "\n",
        "# VOCAB_SIZE = len(vocab)\n",
        "# EMBED_DIM = 100 # As required by the assignment\n",
        "# HIDDEN_SIZE = 256\n",
        "# NUM_CLASSES = 5\n",
        "# EPOCHS = 10 # A few epochs for demonstration\n",
        "# BATCH_SIZE = 32\n",
        "# LEARNING_RATE = 0.0005\n",
        "\n",
        "# # --- Initialization ---\n",
        "\n",
        "# model = RNNClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
        "# loss_fn = SoftmaxCrossEntropy()\n",
        "# optimizer = Adam(\n",
        "#     model.layers,\n",
        "#     learning_rate=0.0005,\n",
        "#     beta1=0.9,\n",
        "#     beta2=0.999,\n",
        "#     epsilon=1e-8,\n",
        "#     clip_value=1.0,      # Clip gradient values between -1.0 and 1.0\n",
        "#     clip_norm=5.0        # Additionally clip gradient norm to 5.0\n",
        "# )\n",
        "\n",
        "# # --- Training Loop ---\n",
        "\n",
        "# num_batches = len(X_train) // BATCH_SIZE\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     epoch_loss = 0\n",
        "#     # Shuffle training data\n",
        "#     permutation = np.random.permutation(len(X_train))\n",
        "#     X_train_shuffled = X_train[permutation]\n",
        "#     y_train_shuffled = y_train[permutation]\n",
        "\n",
        "#     # Create a progress bar\n",
        "#     pbar = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "#     for i in pbar:\n",
        "#         # Create a mini-batch\n",
        "#         start = i * BATCH_SIZE\n",
        "#         end = start + BATCH_SIZE\n",
        "#         X_batch = X_train_shuffled[start:end]\n",
        "#         y_batch = y_train_shuffled[start:end]\n",
        "\n",
        "#         # 1. Forward pass\n",
        "#         logits = model.forward(X_batch, training=True)\n",
        "\n",
        "#         # 2. Compute loss\n",
        "#         loss = loss_fn.forward(logits, y_batch)\n",
        "#         epoch_loss += loss\n",
        "\n",
        "#         # 3. Backward pass\n",
        "#         grad = loss_fn.backward()\n",
        "#         model.backward(grad)\n",
        "\n",
        "#         # 4. Update weights\n",
        "#         optimizer.step()\n",
        "\n",
        "#         # Update progress bar description\n",
        "#         pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
        "\n",
        "#     print(f\"Epoch {epoch+1} Average Loss: {epoch_loss / num_batches:.4f}\")\n",
        "\n",
        "# # --- Save the trained weights ---\n",
        "# if not os.path.exists('saved_weights'):\n",
        "#     os.makedirs('saved_weights')\n",
        "\n",
        "# save_weights(model, 'saved_weights/rnn_model_weights.npz')\n",
        "\n",
        "# # --- Evaluation ---\n",
        "# def evaluate(model, X, y):\n",
        "#     logits = model.forward(X, training=False)\n",
        "#     predictions = np.argmax(logits, axis=1)\n",
        "#     accuracy = np.mean(predictions == y)\n",
        "#     return accuracy\n",
        "\n",
        "# train_accuracy = evaluate(model, X_train[:500], y_train[:500]) # On a subset for speed\n",
        "# test_accuracy = evaluate(model, X_test, y_test)\n",
        "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
        "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5. Model 2 - LSTM from scratch"
      ],
      "metadata": {
        "id": "ECDJixutlB2B"
      },
      "id": "ECDJixutlB2B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. LSTM Layer"
      ],
      "metadata": {
        "id": "WTemaoIXlIMR"
      },
      "id": "WTemaoIXlIMR"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3392e0c2-9d70-4662-876e-81fc671b3855",
      "metadata": {
        "id": "3392e0c2-9d70-4662-876e-81fc671b3855"
      },
      "outputs": [],
      "source": [
        "class LSTM(Layer):\n",
        "    \"\"\"A Long Short-Term Memory (LSTM) layer.\"\"\"\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # We concatenate weights for all 4 gates for efficiency\n",
        "        # W_x maps input to the 4 gates, W_h maps hidden state to the 4 gates\n",
        "        size_sum = input_size + hidden_size\n",
        "        limit_x = np.sqrt(6 / (size_sum))\n",
        "        limit_h = np.sqrt(6 / (hidden_size + hidden_size))\n",
        "\n",
        "        self.params['W_x'] = np.random.uniform(-limit_x, limit_x, (input_size, 4 * hidden_size))\n",
        "        self.params['W_h'] = np.random.uniform(-limit_h, limit_h, (hidden_size, 4 * hidden_size))\n",
        "        self.params['b'] = np.zeros(4 * hidden_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        batch_size, seq_len, _ = inputs.shape\n",
        "        h_size = self.hidden_size\n",
        "\n",
        "        # Caches for backpropagation\n",
        "        self.h_states = np.zeros((batch_size, seq_len + 1, h_size))\n",
        "        self.c_states = np.zeros((batch_size, seq_len + 1, h_size))\n",
        "        self.gates_pre = np.zeros((batch_size, seq_len, 4 * h_size))\n",
        "        self.gates = np.zeros((batch_size, seq_len, 4 * h_size))\n",
        "\n",
        "        # Initial hidden and cell states are zeros\n",
        "        h = self.h_states[:, 0, :]\n",
        "        c = self.c_states[:, 0, :]\n",
        "\n",
        "        for t in range(seq_len):\n",
        "            x_t = inputs[:, t, :]\n",
        "\n",
        "            # Combined matrix multiplication for all gates\n",
        "            pre_activation = x_t @ self.params['W_x'] + h @ self.params['W_h'] + self.params['b']\n",
        "            self.gates_pre[:, t, :] = pre_activation\n",
        "\n",
        "            # Split into individual gates\n",
        "            f_gate = self._sigmoid(pre_activation[:, :h_size])\n",
        "            i_gate = self._sigmoid(pre_activation[:, h_size:2*h_size])\n",
        "            g_gate = np.tanh(pre_activation[:, 2*h_size:3*h_size])\n",
        "            o_gate = self._sigmoid(pre_activation[:, 3*h_size:])\n",
        "            self.gates[:, t, :] = np.hstack((f_gate, i_gate, g_gate, o_gate))\n",
        "\n",
        "            # Update cell and hidden states\n",
        "            c = f_gate * c + i_gate * g_gate\n",
        "            h = o_gate * np.tanh(c)\n",
        "\n",
        "            self.c_states[:, t+1, :] = c\n",
        "            self.h_states[:, t+1, :] = h\n",
        "\n",
        "        return h\n",
        "\n",
        "    def backward(self, grad_h_final):\n",
        "        batch_size, seq_len, _ = self.inputs.shape\n",
        "        h_size = self.hidden_size\n",
        "\n",
        "        # Initialize gradients\n",
        "        self.grads['W_x'] = np.zeros_like(self.params['W_x'])\n",
        "        self.grads['W_h'] = np.zeros_like(self.params['W_h'])\n",
        "        self.grads['b'] = np.zeros_like(self.params['b'])\n",
        "        grad_inputs = np.zeros_like(self.inputs)\n",
        "\n",
        "        # Initialize gradients for hidden and cell states flowing backwards\n",
        "        grad_h = grad_h_final\n",
        "        grad_c = np.zeros_like(grad_h)\n",
        "\n",
        "        for t in reversed(range(seq_len)):\n",
        "            # Retrieve cached values for this timestep\n",
        "            h_prev = self.h_states[:, t, :]\n",
        "            c_prev = self.c_states[:, t, :]\n",
        "            c_t = self.c_states[:, t+1, :]\n",
        "            x_t = self.inputs[:, t, :]\n",
        "\n",
        "            f_t, i_t, g_t, o_t = (\n",
        "                self.gates[:, t, :h_size],\n",
        "                self.gates[:, t, h_size:2*h_size],\n",
        "                self.gates[:, t, 2*h_size:3*h_size],\n",
        "                self.gates[:, t, 3*h_size:]\n",
        "            )\n",
        "\n",
        "            # Backprop through h_t = o_t * tanh(c_t)\n",
        "            grad_o = grad_h * np.tanh(c_t)\n",
        "            grad_c += grad_h * o_t * (1 - np.tanh(c_t)**2)\n",
        "\n",
        "            # Backprop through c_t = f_t * c_prev + i_t * g_t\n",
        "            grad_f = grad_c * c_prev\n",
        "            grad_i = grad_c * g_t\n",
        "            grad_g = grad_c * i_t\n",
        "            grad_c_prev = grad_c * f_t\n",
        "\n",
        "            # Backprop through gate activations\n",
        "            d_o_pre = grad_o * o_t * (1 - o_t) # Sigmoid derivative\n",
        "            d_g_pre = grad_g * (1 - g_t**2)      # Tanh derivative\n",
        "            d_i_pre = grad_i * i_t * (1 - i_t) # Sigmoid derivative\n",
        "            d_f_pre = grad_f * f_t * (1 - f_t) # Sigmoid derivative\n",
        "\n",
        "            # Concatenate gate gradients\n",
        "            d_gates = np.hstack((d_f_pre, d_i_pre, d_g_pre, d_o_pre))\n",
        "\n",
        "            # Calculate gradients for parameters and inputs\n",
        "            self.grads['b'] += np.sum(d_gates, axis=0)\n",
        "            self.grads['W_x'] += x_t.T @ d_gates\n",
        "            self.grads['W_h'] += h_prev.T @ d_gates\n",
        "\n",
        "            grad_inputs[:, t, :] = d_gates @ self.params['W_x'].T\n",
        "\n",
        "            # Update gradients for the next (previous) timestep\n",
        "            grad_h = d_gates @ self.params['W_h'].T\n",
        "            grad_c = grad_c_prev\n",
        "\n",
        "        return grad_inputs\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37c3e5c9-6406-4160-bfaf-9dd615a695a7",
      "metadata": {
        "id": "37c3e5c9-6406-4160-bfaf-9dd615a695a7"
      },
      "source": [
        "### 2. Assembling LSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3d4fb9b0-8479-43d7-ac04-2f1707b81994",
      "metadata": {
        "id": "3d4fb9b0-8479-43d7-ac04-2f1707b81994"
      },
      "outputs": [],
      "source": [
        "class LSTMClassifier:\n",
        "    \"\"\"A complete LSTM model for classification.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n",
        "        self.embedding = Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = LSTM(embed_dim, hidden_size)\n",
        "        self.dense = Dense(hidden_size, num_classes)\n",
        "        self.layers = [self.embedding, self.lstm, self.dense]\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.embedding.forward(inputs)\n",
        "        x = self.lstm.forward(x)\n",
        "        x = self.dense.forward(x)\n",
        "        return x\n",
        "\n",
        "    def backward(self, grad):\n",
        "        grad = self.dense.backward(grad)\n",
        "        grad = self.lstm.backward(grad)\n",
        "        self.embedding.backward(grad)\n",
        "\n",
        "# --- Model and Training Hyperparameters ---\n",
        "# Same as before, but we can give the model a new name\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_CLASSES = 5\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# --- Initialization ---\n",
        "lstm_model = LSTMClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
        "loss_fn = SoftmaxCrossEntropy()\n",
        "optimizer = Adam(lstm_model.layers, learning_rate=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Training the LSTM Classifier and Weight Download"
      ],
      "metadata": {
        "id": "qEBlVh7g4lmv"
      },
      "id": "qEBlVh7g4lmv"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f0c66088-6a2c-44ff-8497-1c4df25ab57f",
      "metadata": {
        "id": "f0c66088-6a2c-44ff-8497-1c4df25ab57f"
      },
      "outputs": [],
      "source": [
        "# # --- Training Loop (This code is identical to the RNN training loop) ---\n",
        "# num_batches = len(X_train) // BATCH_SIZE\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     epoch_loss = 0\n",
        "#     permutation = np.random.permutation(len(X_train))\n",
        "#     X_train_shuffled = X_train[permutation]\n",
        "#     y_train_shuffled = y_train[permutation]\n",
        "\n",
        "#     pbar = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{EPOCHS} (LSTM)\")\n",
        "\n",
        "#     for i in pbar:\n",
        "#         start = i * BATCH_SIZE\n",
        "#         end = start + BATCH_SIZE\n",
        "#         X_batch, y_batch = X_train_shuffled[start:end], y_train_shuffled[start:end]\n",
        "\n",
        "#         logits = lstm_model.forward(X_batch)\n",
        "#         loss = loss_fn.forward(logits, y_batch)\n",
        "#         epoch_loss += loss\n",
        "\n",
        "#         grad = loss_fn.backward()\n",
        "#         lstm_model.backward(grad)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
        "\n",
        "#     print(f\"Epoch {epoch+1} Average Loss: {epoch_loss / num_batches:.4f}\")\n",
        "\n",
        "# # --- Save and Evaluate ---\n",
        "# save_weights(lstm_model, 'saved_weights/lstm_model_weights.npz')\n",
        "\n",
        "# # --- Evaluation ---\n",
        "# def evaluate(model, X, y):\n",
        "#     logits = model.forward(X)\n",
        "#     predictions = np.argmax(logits, axis=1)\n",
        "#     accuracy = np.mean(predictions == y)\n",
        "#     return accuracy\n",
        "\n",
        "# print(\"\\n--- LSTM Model Evaluation ---\")\n",
        "# train_accuracy = evaluate(lstm_model, X_train[:500], y_train[:500])\n",
        "# test_accuracy = evaluate(lstm_model, X_test, y_test)\n",
        "# print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab60ffd-79e9-45d4-9c64-3434411664ec",
      "metadata": {
        "id": "6ab60ffd-79e9-45d4-9c64-3434411664ec"
      },
      "source": [
        "## Part 5. Model 3 - Transformer from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dad4560-3d12-4d84-bb37-66cc9954db3b",
      "metadata": {
        "id": "3dad4560-3d12-4d84-bb37-66cc9954db3b"
      },
      "source": [
        "### 1. Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1a3d9879-a8ad-44f2-95d7-737c6da3e36b",
      "metadata": {
        "id": "1a3d9879-a8ad-44f2-95d7-737c6da3e36b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class PositionalEncoding(Layer):\n",
        "    \"\"\"\n",
        "    Injects positional information into the input embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_seq_len, embed_dim):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.max_seq_len = max_seq_len\n",
        "\n",
        "        # Pre-calculate the positional encoding matrix\n",
        "        pe = np.zeros((max_seq_len, embed_dim))\n",
        "        position = np.arange(0, max_seq_len).reshape(-1, 1)\n",
        "        div_term = np.exp(np.arange(0, embed_dim, 2) * -(np.log(10000.0) / embed_dim))\n",
        "\n",
        "        pe[:, 0::2] = np.sin(position * div_term)\n",
        "        pe[:, 1::2] = np.cos(position * div_term)\n",
        "\n",
        "        # Add a batch dimension for broadcasting\n",
        "        self.pe = pe.reshape(1, max_seq_len, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Adds positional encoding to the input.\n",
        "        x shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        # x is the output from the embedding layer\n",
        "        self.inputs = x\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        # Add the pre-computed encodings to the input embeddings\n",
        "        return x + self.pe[:, :seq_len, :]\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Passes the gradient through, as this layer has no trainable parameters.\n",
        "        \"\"\"\n",
        "        # The gradient of the input is just the upstream gradient,\n",
        "        # as the operation is a simple addition.\n",
        "        return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a7cd6e2-b36c-4940-848d-c97e5fbb9d47",
      "metadata": {
        "id": "5a7cd6e2-b36c-4940-848d-c97e5fbb9d47"
      },
      "source": [
        "### 2. Multi-Head Self Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f0592b81-3e19-454f-a201-8f608d51f8ed",
      "metadata": {
        "id": "f0592b81-3e19-454f-a201-8f608d51f8ed"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Numerically stable softmax for the last axis.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
        "    return e_x / np.sum(e_x, axis=-1, keepdims=True)\n",
        "\n",
        "class MultiHeadAttention(Layer):\n",
        "    \"\"\"\n",
        "    Multi-Head Self-Attention Layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads.\"\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Xavier initialization\n",
        "        xavier_std = np.sqrt(2.0 / (embed_dim * 2))\n",
        "\n",
        "        # We can combine W_q, W_k, W_v into one matrix for efficiency\n",
        "        self.params['W_qkv'] = np.random.randn(embed_dim, embed_dim * 3) * xavier_std\n",
        "        self.params['W_o'] = np.random.randn(embed_dim, embed_dim) * xavier_std\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass for Multi-Head Attention.\n",
        "        x shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        self.x_shape = x.shape # Store original shape\n",
        "\n",
        "        # 1. Project to Q, K, V\n",
        "        qkv = x @ self.params['W_qkv']\n",
        "\n",
        "        # 2. Reshape and split Q, K, V for each head\n",
        "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.transpose(2, 0, 3, 1, 4) # (3, batch_size, num_heads, seq_len, head_dim)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # 3. Scaled Dot-Product Attention\n",
        "        scores = (q @ k.transpose(0, 1, 3, 2)) / np.sqrt(self.head_dim)\n",
        "\n",
        "        # 4. Apply softmax to get attention weights\n",
        "        self.attention_weights = softmax(scores)\n",
        "\n",
        "        # 5. Apply weights to values\n",
        "        weighted_v = self.attention_weights @ v\n",
        "\n",
        "        # 6. Concatenate heads\n",
        "        # Transpose back: (batch_size, seq_len, num_heads, head_dim)\n",
        "        weighted_v = weighted_v.transpose(0, 2, 1, 3)\n",
        "        # Reshape to (batch_size, seq_len, embed_dim)\n",
        "        concat_v = weighted_v.reshape(batch_size, seq_len, self.embed_dim)\n",
        "\n",
        "        # 7. Final linear projection\n",
        "        output = concat_v @ self.params['W_o']\n",
        "\n",
        "        # Cache values for backward pass\n",
        "        self.cache = (x, q, k, v, concat_v)\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"\n",
        "        Backward pass for Multi-Head Attention. (This is complex!)\n",
        "        grad_output shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        x, q, k, v, concat_v = self.cache\n",
        "        batch_size, seq_len, _ = self.x_shape\n",
        "\n",
        "        # 1. Gradient of the final projection\n",
        "        self.grads['W_o'] = concat_v.reshape(-1, self.embed_dim).T @ grad_output.reshape(-1, self.embed_dim)\n",
        "        grad_concat_v = grad_output @ self.params['W_o'].T\n",
        "\n",
        "        # 2. Un-concatenate heads\n",
        "        grad_weighted_v = grad_concat_v.reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        grad_weighted_v = grad_weighted_v.transpose(0, 2, 1, 3) # (batch, heads, seq_len, head_dim)\n",
        "\n",
        "        # 3. Gradient through attention_weights @ v\n",
        "        grad_attention_weights = grad_weighted_v @ v.transpose(0, 1, 3, 2)\n",
        "        grad_v = self.attention_weights.transpose(0, 1, 3, 2) @ grad_weighted_v\n",
        "\n",
        "        # 4. Gradient through softmax\n",
        "        s = self.attention_weights\n",
        "        grad_scores = s * (grad_attention_weights - np.sum(grad_attention_weights * s, axis=-1, keepdims=True))\n",
        "\n",
        "        # 5. Gradient through scaling\n",
        "        grad_scores /= np.sqrt(self.head_dim)\n",
        "\n",
        "        # 6. Gradient through q @ k.T\n",
        "        grad_q = grad_scores @ k\n",
        "        grad_k = grad_scores.transpose(0, 1, 3, 2) @ q\n",
        "\n",
        "        # 7. Combine head gradients for Q, K, V\n",
        "        # Transpose from (batch, head, seq, dim) to (3, batch, head, seq, dim)\n",
        "        grad_qkv = np.array([grad_q, grad_k, grad_v])\n",
        "        # Transpose back to (batch, seq, 3, head, dim)\n",
        "        grad_qkv = grad_qkv.transpose(1, 3, 0, 2, 4)\n",
        "        # Reshape to (batch, seq, 3 * embed_dim)\n",
        "        grad_qkv = grad_qkv.reshape(batch_size, seq_len, 3 * self.embed_dim)\n",
        "\n",
        "        # 8. Gradient of the initial projection W_qkv\n",
        "        self.grads['W_qkv'] = x.reshape(-1, self.embed_dim).T @ grad_qkv.reshape(-1, 3 * self.embed_dim)\n",
        "\n",
        "        # 9. Gradient for the input x\n",
        "        grad_x = grad_qkv @ self.params['W_qkv'].T\n",
        "\n",
        "        return grad_x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7066c839-d1f4-4af5-95ac-6a8c2213a42a",
      "metadata": {
        "id": "7066c839-d1f4-4af5-95ac-6a8c2213a42a"
      },
      "source": [
        "### 3. Position Wise Feedforward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c1b42fe4-b10c-4d81-abbe-d2a9187a104b",
      "metadata": {
        "id": "c1b42fe4-b10c-4d81-abbe-d2a9187a104b"
      },
      "outputs": [],
      "source": [
        "class PositionwiseFeedForward(Layer):\n",
        "    \"\"\"\n",
        "    Implements the Position-wise Feed-Forward Network.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, ffn_dim):\n",
        "        super().__init__()\n",
        "        # He initialization for ReLU\n",
        "        he_std_1 = np.sqrt(2.0 / embed_dim)\n",
        "        he_std_2 = np.sqrt(2.0 / ffn_dim)\n",
        "\n",
        "        self.params['W_1'] = np.random.randn(embed_dim, ffn_dim) * he_std_1\n",
        "        self.params['b_1'] = np.zeros(ffn_dim)\n",
        "        self.params['W_2'] = np.random.randn(ffn_dim, embed_dim) * he_std_2\n",
        "        self.params['b_2'] = np.zeros(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_len, embed_dim)\n",
        "        \"\"\"\n",
        "        # First linear layer + ReLU\n",
        "        linear_1 = x @ self.params['W_1'] + self.params['b_1']\n",
        "        relu_out = np.maximum(0, linear_1) # ReLU activation\n",
        "\n",
        "        # Second linear layer\n",
        "        output = relu_out @ self.params['W_2'] + self.params['b_2']\n",
        "\n",
        "        # Cache for backprop\n",
        "        self.cache = (x, linear_1, relu_out)\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        x, linear_1, relu_out = self.cache\n",
        "\n",
        "        # Backprop through second linear layer\n",
        "        self.grads['W_2'] = relu_out.reshape(-1, relu_out.shape[-1]).T @ grad_output.reshape(-1, grad_output.shape[-1])\n",
        "        self.grads['b_2'] = np.sum(grad_output, axis=(0, 1))\n",
        "        grad_relu_out = grad_output @ self.params['W_2'].T\n",
        "\n",
        "        # Backprop through ReLU\n",
        "        grad_linear_1 = grad_relu_out * (linear_1 > 0)\n",
        "\n",
        "        # Backprop through first linear layer\n",
        "        self.grads['W_1'] = x.reshape(-1, x.shape[-1]).T @ grad_linear_1.reshape(-1, grad_linear_1.shape[-1])\n",
        "        self.grads['b_1'] = np.sum(grad_linear_1, axis=(0, 1))\n",
        "\n",
        "        # Gradient to pass to the previous layer\n",
        "        grad_x = grad_linear_1 @ self.params['W_1'].T\n",
        "        return grad_x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c27848-69dc-44e3-954f-e18ce90dffba",
      "metadata": {
        "id": "69c27848-69dc-44e3-954f-e18ce90dffba"
      },
      "source": [
        "### 4. Layer Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "71f25d8d-bce8-41e8-97a1-0429128edcf8",
      "metadata": {
        "id": "71f25d8d-bce8-41e8-97a1-0429128edcf8"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization(Layer):\n",
        "    \"\"\"\n",
        "    Implements Layer Normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, epsilon=1e-5):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        # Learnable parameters: gamma (scale) and beta (shift)\n",
        "        self.params['gamma'] = np.ones(embed_dim)\n",
        "        self.params['beta'] = np.zeros(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Calculate mean and variance along the last dimension (features)\n",
        "        mean = np.mean(x, axis=-1, keepdims=True)\n",
        "        var = np.var(x, axis=-1, keepdims=True)\n",
        "        std = np.sqrt(var + self.epsilon)\n",
        "\n",
        "        # Normalize x\n",
        "        x_norm = (x - mean) / std\n",
        "\n",
        "        # Apply scale and shift\n",
        "        output = self.params['gamma'] * x_norm + self.params['beta']\n",
        "\n",
        "        self.cache = (x, mean, std, x_norm)\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        x, mean, std, x_norm = self.cache\n",
        "        N, T, D = x.shape\n",
        "\n",
        "        # Gradients for learnable parameters gamma and beta\n",
        "        self.grads['gamma'] = np.sum(grad_output * x_norm, axis=(0, 1))\n",
        "        self.grads['beta'] = np.sum(grad_output, axis=(0, 1))\n",
        "\n",
        "        # Gradient for the normalized output\n",
        "        grad_x_norm = grad_output * self.params['gamma']\n",
        "\n",
        "        # Gradient for the standard deviation\n",
        "        grad_std = -np.sum(grad_x_norm * (x - mean), axis=-1, keepdims=True) / (std**2)\n",
        "\n",
        "        # Gradient for the variance\n",
        "        grad_var = 0.5 * grad_std / std\n",
        "\n",
        "        # Gradient for the mean\n",
        "        grad_mean = -np.sum(grad_x_norm / std, axis=-1, keepdims=True) - (2.0/D) * grad_var * np.sum(x - mean, axis=-1, keepdims=True)\n",
        "\n",
        "        # Gradient for the input x\n",
        "        grad_x = (grad_x_norm / std) + (2.0/D) * grad_var * (x - mean) + (1.0/D) * grad_mean\n",
        "\n",
        "        return grad_x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c7482bb-3b96-44c1-8781-5917a681d911",
      "metadata": {
        "id": "0c7482bb-3b96-44c1-8781-5917a681d911"
      },
      "source": [
        "### 5. Transformer Encoder Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "bafcccc5-72e4-481a-af9b-5291f30c029f",
      "metadata": {
        "id": "bafcccc5-72e4-481a-af9b-5291f30c029f"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderBlock(Layer):\n",
        "    \"\"\"\n",
        "    A single block of the Transformer Encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, embed_dim, num_heads, ffn_dim, dropout_p=0.1):\n",
        "        # We REMOVE the super().__init__() call here.\n",
        "        # This class is a container and its params/grads are handled by the @property methods.\n",
        "\n",
        "        self.attention = MultiHeadAttention(embed_dim, num_heads)\n",
        "        self.norm1 = LayerNormalization(embed_dim)\n",
        "        self.feed_forward = PositionwiseFeedForward(embed_dim, ffn_dim)\n",
        "        self.norm2 = LayerNormalization(embed_dim)\n",
        "        self.dropout1 = Dropout(dropout_p)\n",
        "        self.dropout2 = Dropout(dropout_p)\n",
        "\n",
        "        # Store sub-layers in a list to make collecting params/grads easy\n",
        "        self.sub_layers = [self.attention, self.norm1, self.feed_forward, self.norm2, self.dropout1, self.dropout2]\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        # 1. Attention sub-layer\n",
        "        attn_output = self.attention.forward(x)\n",
        "        attn_output = self.dropout1.forward(attn_output, training=training)\n",
        "        # Residual connection and normalization\n",
        "        sublayer1_output = self.norm1.forward(x + attn_output)\n",
        "\n",
        "        # 2. Feed-forward sub-layer\n",
        "        ffn_output = self.feed_forward.forward(sublayer1_output)\n",
        "        ffn_output = self.dropout2.forward(ffn_output, training=training)\n",
        "        # Residual connection and normalization\n",
        "        output = self.norm2.forward(sublayer1_output + ffn_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        # Backpropagate in reverse order\n",
        "        grad_sublayer2 = self.norm2.backward(grad_output)\n",
        "        grad_sublayer1_output = grad_sublayer2\n",
        "        grad_ffn_output = grad_sublayer2\n",
        "\n",
        "        grad_ffn_output = self.dropout2.backward(grad_ffn_output)\n",
        "        grad_sublayer1_output += self.feed_forward.backward(grad_ffn_output)\n",
        "\n",
        "        grad_sublayer1 = self.norm1.backward(grad_sublayer1_output)\n",
        "        grad_x = grad_sublayer1\n",
        "        grad_attn_output = grad_sublayer1\n",
        "\n",
        "        grad_attn_output = self.dropout1.backward(grad_attn_output)\n",
        "        grad_x += self.attention.backward(grad_attn_output)\n",
        "\n",
        "        return grad_x\n",
        "\n",
        "    # These properties dynamically gather params and grads from all sub-layers\n",
        "    @property\n",
        "    def params(self):\n",
        "        params = {}\n",
        "        for i, layer in enumerate(self.sub_layers):\n",
        "            # Use layer's class name for better readability\n",
        "            layer_name = f\"{layer.__class__.__name__}_{i}\"\n",
        "            for key, val in layer.params.items():\n",
        "                params[f'{layer_name}_{key}'] = val\n",
        "        return params\n",
        "\n",
        "    @property\n",
        "    def grads(self):\n",
        "        grads = {}\n",
        "        for i, layer in enumerate(self.sub_layers):\n",
        "            layer_name = f\"{layer.__class__.__name__}_{i}\"\n",
        "            for key, val in layer.grads.items():\n",
        "                grads[f'{layer_name}_{key}'] = val\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178692f2-13be-40db-b6f2-0b05067de147",
      "metadata": {
        "id": "178692f2-13be-40db-b6f2-0b05067de147"
      },
      "source": [
        "### 6. Global Average Pooling Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1e13e687-dcc1-4cf5-aad9-13fc16c7195a",
      "metadata": {
        "id": "1e13e687-dcc1-4cf5-aad9-13fc16c7195a"
      },
      "outputs": [],
      "source": [
        "class GlobalAveragePooling1D(Layer):\n",
        "    \"\"\"\n",
        "    Performs global average pooling over the time/sequence dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_len, embed_dim)\n",
        "        output shape: (batch_size, embed_dim)\n",
        "        \"\"\"\n",
        "        self.cache_input_shape = x.shape\n",
        "        return np.mean(x, axis=1)\n",
        "\n",
        "    def backward(self, grad):\n",
        "        \"\"\"\n",
        "        Distributes the gradient evenly back across the sequence length.\n",
        "        grad shape: (batch_size, embed_dim)\n",
        "        \"\"\"\n",
        "        _, seq_len, _ = self.cache_input_shape\n",
        "\n",
        "        # Expand grad to be broadcastable to the input shape\n",
        "        grad_expanded = np.expand_dims(grad, 1)\n",
        "\n",
        "        # The gradient for each time step is the upstream grad divided by the sequence length\n",
        "        grad_input = np.tile(grad_expanded, (1, seq_len, 1)) / seq_len\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9217eeb5-f0b8-4ff4-a6e7-f9681c0a5db3",
      "metadata": {
        "id": "9217eeb5-f0b8-4ff4-a6e7-f9681c0a5db3"
      },
      "source": [
        "### 7. Transformer Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "4e6962a4-c29e-483a-9553-d65f0557fdba",
      "metadata": {
        "id": "4e6962a4-c29e-483a-9553-d65f0557fdba"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier:\n",
        "    \"\"\"\n",
        "    A full Transformer-based text classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, max_seq_len, embed_dim, num_heads, ffn_dim, num_layers, num_classes, dropout_p=0.1):\n",
        "        self.layers = []\n",
        "\n",
        "        # 1. Input layers\n",
        "        self.embedding = Embedding(vocab_size, embed_dim)\n",
        "        self.pos_encoding = PositionalEncoding(max_seq_len, embed_dim)\n",
        "        self.embed_dropout = Dropout(dropout_p)\n",
        "        self.layers.extend([self.embedding, self.pos_encoding, self.embed_dropout])\n",
        "\n",
        "        # 2. Stack of N Transformer Encoder Blocks\n",
        "        self.encoder_blocks = []\n",
        "        for _ in range(num_layers):\n",
        "            block = TransformerEncoderBlock(embed_dim, num_heads, ffn_dim, dropout_p)\n",
        "            self.encoder_blocks.append(block)\n",
        "            self.layers.append(block)\n",
        "\n",
        "        # 3. Output layers\n",
        "        self.pooling = GlobalAveragePooling1D()\n",
        "        self.dense = Dense(embed_dim, num_classes)\n",
        "        self.layers.extend([self.pooling, self.dense])\n",
        "\n",
        "    def forward(self, inputs, training=True):\n",
        "        # Input processing\n",
        "        x = self.embedding.forward(inputs)\n",
        "        x = self.pos_encoding.forward(x)\n",
        "        x = self.embed_dropout.forward(x, training=training)\n",
        "\n",
        "        # Pass through the stack of encoder blocks\n",
        "        for block in self.encoder_blocks:\n",
        "            x = block.forward(x, training=training)\n",
        "\n",
        "        # Pooling and final classification\n",
        "        x = self.pooling.forward(x)\n",
        "        logits = self.dense.forward(x)\n",
        "        return logits\n",
        "\n",
        "    def backward(self, grad):\n",
        "        # Backpropagate in reverse order\n",
        "        grad = self.dense.backward(grad)\n",
        "        grad = self.pooling.backward(grad)\n",
        "\n",
        "        for block in reversed(self.encoder_blocks):\n",
        "            grad = block.backward(grad)\n",
        "\n",
        "        grad = self.embed_dropout.backward(grad)\n",
        "        grad = self.pos_encoding.backward(grad)\n",
        "        self.embedding.backward(grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35d56552-d7fd-46c0-acad-5388ce9635b1",
      "metadata": {
        "id": "35d56552-d7fd-46c0-acad-5388ce9635b1"
      },
      "source": [
        "### 8. Model Training and Weight Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "23506e1b-bb3b-463b-a561-6ad505073ed4",
      "metadata": {
        "id": "23506e1b-bb3b-463b-a561-6ad505073ed4"
      },
      "outputs": [],
      "source": [
        "# from tqdm.notebook import tqdm\n",
        "# import os\n",
        "\n",
        "# MAX_SEQ_LEN = 50\n",
        "\n",
        "# VOCAB_SIZE = len(vocab)\n",
        "# EMBED_DIM = 100\n",
        "# NUM_HEADS = 5          # Number of attention heads (standard choice)\n",
        "# FFN_DIM = 400         # Hidden layer size in FFN (usually 4 * embed_dim)\n",
        "# NUM_LAYERS = 4         # Number of Transformer blocks to stack (a deep model)\n",
        "# NUM_CLASSES = 5\n",
        "# DROPOUT_P = 0.1        # Standard dropout for Transformers\n",
        "\n",
        "# EPOCHS = 10            # Train for longer to allow the model to converge\n",
        "# BATCH_SIZE = 64        # Can use a larger batch size if memory allows\n",
        "# LEARNING_RATE = 0.0001 # Transformers often prefer a smaller learning rate\n",
        "\n",
        "# # --- Initialization ---\n",
        "\n",
        "# print(\"Initializing Transformer Classifier...\")\n",
        "# transformer_model = TransformerClassifier(\n",
        "#     vocab_size=VOCAB_SIZE,\n",
        "#     max_seq_len=MAX_SEQ_LEN,\n",
        "#     embed_dim=EMBED_DIM,\n",
        "#     num_heads=NUM_HEADS,\n",
        "#     ffn_dim=FFN_DIM,\n",
        "#     num_layers=NUM_LAYERS,\n",
        "#     num_classes=NUM_CLASSES,\n",
        "#     dropout_p=DROPOUT_P\n",
        "# )\n",
        "\n",
        "# loss_fn = SoftmaxCrossEntropy()\n",
        "# optimizer = Adam(\n",
        "#     transformer_model.layers,\n",
        "#     learning_rate=LEARNING_RATE,\n",
        "#     beta1=0.9,\n",
        "#     beta2=0.98,        # Values commonly used for Transformers\n",
        "#     epsilon=1e-9,      # Values commonly used for Transformers\n",
        "#     clip_norm=1.0      # Gradient norm clipping is very important\n",
        "# )\n",
        "\n",
        "# # --- Training Loop ---\n",
        "# num_batches = len(X_train) // BATCH_SIZE\n",
        "\n",
        "# for epoch in range(EPOCHS):\n",
        "#     epoch_loss = 0\n",
        "#     permutation = np.random.permutation(len(X_train))\n",
        "#     X_train_shuffled = X_train[permutation]\n",
        "#     y_train_shuffled = y_train[permutation]\n",
        "\n",
        "#     pbar = tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{EPOCHS} (transformer)\")\n",
        "\n",
        "#     for i in pbar:\n",
        "#         start = i * BATCH_SIZE\n",
        "#         end = start + BATCH_SIZE\n",
        "#         X_batch, y_batch = X_train_shuffled[start:end], y_train_shuffled[start:end]\n",
        "\n",
        "#         logits = transformer_model.forward(X_batch, training=True)\n",
        "#         loss = loss_fn.forward(logits, y_batch)\n",
        "#         epoch_loss += loss\n",
        "\n",
        "#         grad = loss_fn.backward()\n",
        "#         transformer_model.backward(grad)\n",
        "#         optimizer.step()\n",
        "\n",
        "#         pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
        "\n",
        "#     print(f\"Epoch {epoch+1} Average Loss: {epoch_loss / num_batches:.4f}\")\n",
        "\n",
        "# # --- Save the trained weights ---\n",
        "# if not os.path.exists('saved_weights'):\n",
        "#     os.makedirs('saved_weights')\n",
        "\n",
        "# # --- Save and Evaluate ---\n",
        "# save_weights(transformer_model, 'saved_weights/transformer_model_weights.npz')\n",
        "\n",
        "# # --- Evaluation ---\n",
        "# def evaluate(model, X, y):\n",
        "#     logits = model.forward(X, training=False)\n",
        "#     predictions = np.argmax(logits, axis=1)\n",
        "#     accuracy = np.mean(predictions == y)\n",
        "#     return accuracy\n",
        "\n",
        "# print(\"\\n--- Transformer Model Evaluation ---\")\n",
        "# train_accuracy = evaluate(transformer_model, X_train[:500], y_train[:500])\n",
        "# test_accuracy = evaluate(transformer_model, X_test, y_test)\n",
        "# print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "# print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fbe1a22b-ba9b-4deb-9128-9fadbd2784fd",
      "metadata": {
        "id": "fbe1a22b-ba9b-4deb-9128-9fadbd2784fd"
      },
      "outputs": [],
      "source": [
        "# print(\"Evaluating on the test set...\")\n",
        "# logits_test = transformer_model.forward(X_test)\n",
        "# predictions_test = np.argmax(logits_test, axis=1)\n",
        "\n",
        "\n",
        "# # Class Names\n",
        "# class_labels = ['Neutral','Positive','Extremely Negative','Negative','Extremely Positive']\n",
        "\n",
        "# # Generate and print the report\n",
        "# print(\"\\n--- Classification Report ---\")\n",
        "# classification_report_from_scratch(y_test, predictions_test, class_names=class_labels)\n",
        "\n",
        "\n",
        "# test_accuracy = np.mean(predictions_test == y_test)\n",
        "# print(f\"\\nFinal Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c4c6efa-1aa1-4e8e-97c1-65bb9171193e",
      "metadata": {
        "id": "7c4c6efa-1aa1-4e8e-97c1-65bb9171193e"
      },
      "source": [
        "## Loading Weights for Each Model from Github Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc3dc4e9-bf15-445b-8cfc-0f59cd25fc60",
      "metadata": {
        "id": "bc3dc4e9-bf15-445b-8cfc-0f59cd25fc60"
      },
      "source": [
        "### Defining Load Weight Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "c7835247-5cf4-4dcc-bfd1-f42dc6c38a49",
      "metadata": {
        "id": "c7835247-5cf4-4dcc-bfd1-f42dc6c38a49"
      },
      "outputs": [],
      "source": [
        "def load_weights_from_url(model, url):\n",
        "    \"\"\"Downloads and loads weights from a URL.\"\"\"\n",
        "    print(f\"Downloading weights from {url}...\")\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    with io.BytesIO(response.content) as f:\n",
        "        data = np.load(f)\n",
        "        for i, layer in enumerate(model.layers):\n",
        "            for key in layer.params:\n",
        "                layer.params[key] = data[f'layer_{i}_{key}']\n",
        "    print(\"Weights loaded successfully from URL.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3616063-dbae-4df3-923d-9ab7fe59c30e",
      "metadata": {
        "id": "e3616063-dbae-4df3-923d-9ab7fe59c30e"
      },
      "source": [
        "### For RNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "# Define Model Hyperparameters\n",
        "# These must match the parameters used to train the saved model.\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_SIZE = 256\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# --- 2. Initialize a New, Untrained Model Instance ---\n",
        "print(\"Initializing a model structure...\")\n",
        "rnn_model_from_git = RNNClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
        "\n",
        "# --- 3. Define the Raw URL for the Weights File ---\n",
        "rnn_weights_url = \"https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/rnn_model_weights.npz\"\n",
        "\n",
        "# --- Evaluation ---\n",
        "\n",
        "def evaluate_and_report_rnn(model, X, y, class_names=None, batch_size=64):\n",
        "    \"\"\"\n",
        "    Evaluates the RNN model in mini-batches, prints a full classification report,\n",
        "    and returns the final accuracy.\n",
        "    \"\"\"\n",
        "    num_samples = len(X)\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(f\"Evaluating on {num_samples} samples in batches of {batch_size}...\")\n",
        "    pbar = tqdm(range(num_batches), desc=\"RNN Evaluation Progress\")\n",
        "\n",
        "    for i in pbar:\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        X_batch = X[start_idx:end_idx]\n",
        "\n",
        "        # NOTE: The original RNN forward pass does not have a 'training' flag.\n",
        "        logits = model.forward(X_batch)\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "\n",
        "    # --- Generate the Detailed Report ---\n",
        "    print(\"\\n--- Classification Report for RNN from GitHub ---\")\n",
        "    classification_report_from_scratch(y, all_predictions, class_names=class_names)\n",
        "\n",
        "    # Calculate and return the final accuracy\n",
        "    accuracy = np.mean(all_predictions == y)\n",
        "    return accuracy\n",
        "\n",
        "# --- 4. Load the Weights from the URL ---\n",
        "try:\n",
        "    print(\"Attempting to load RNN weights from URL...\")\n",
        "    load_weights_from_url(rnn_model_from_git, rnn_weights_url)\n",
        "    print(\" RNN weights successfully loaded.\")\n",
        "\n",
        "    # --- 5. Evaluate the Model's Performance ---\n",
        "\n",
        "    # Define class names for the report\n",
        "    class_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
        "\n",
        "    # Call the new function to get the report and accuracy\n",
        "    test_accuracy = evaluate_and_report_rnn(\n",
        "        rnn_model_from_git,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        class_names=class_labels\n",
        "    )\n",
        "\n",
        "    # --- 6. Show the Final Accuracy ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Final RNN Model Accuracy from GitHub: {test_accuracy:.4f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n An error occurred: {e}\")\n",
        "    print(\"Please ensure the URL is correct and the file is accessible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612,
          "referenced_widgets": [
            "bc105a014c36445f879d644a7bf581f4",
            "59b604b7990344fd8fe51e2cf69f762d",
            "879fb89c22e74cf1a842d2c9cee9fc31",
            "8839ceb84be14d959a548e3165657c29",
            "31c301ed0dd64cdd920b0c7b1d87b338",
            "7820741132d742b28d9642047aa6689c",
            "f02bd68531684e918b0365e2c5fefacf",
            "8b7776cb87394422a45d60c0a043124b",
            "4d0b1b688db540d292e552afda837186",
            "2530b22b0c5b463db45d90ea5c8448cd",
            "53aaa59cd2774457953c8e9e06200d89"
          ]
        },
        "id": "j5HdTvJv3cpz",
        "outputId": "1f7d1885-1d5c-4ab2-b1ef-367597f38d34"
      },
      "id": "j5HdTvJv3cpz",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing a model structure...\n",
            "Attempting to load RNN weights from URL...\n",
            "Downloading weights from https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/rnn_model_weights.npz...\n",
            "Downloaded file contains the following keys: ['layer_0_W', 'layer_1_W_xh', 'layer_1_W_hh', 'layer_1_b_h', 'layer_3_W', 'layer_3_b']\n",
            "\n",
            "--- Attempting to match and load weights into model layers ---\n",
            " Successfully loaded layer_0_W\n",
            " Successfully loaded layer_1_W_xh\n",
            " Successfully loaded layer_1_W_hh\n",
            " Successfully loaded layer_1_b_h\n",
            " Successfully loaded layer_3_W\n",
            " Successfully loaded layer_3_b\n",
            " RNN weights successfully loaded.\n",
            "Evaluating on 3798 samples in batches of 64...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RNN Evaluation Progress:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc105a014c36445f879d644a7bf581f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classification Report for RNN from GitHub ---\n",
            "                     precision      recall    f1-score     support\n",
            "\n",
            "Extremely Negative        0.22        0.11        0.15         592\n",
            "Negative                  0.30        0.22        0.25        1041\n",
            "Neutral                   0.15        0.10        0.12         619\n",
            "Positive                  0.25        0.54        0.35         947\n",
            "Extremely Positive        0.24        0.12        0.16         599\n",
            "\n",
            "accuracy                                          0.25        3798\n",
            "micro avg                 0.25        0.25        0.25        3798\n",
            "macro avg                 0.23        0.22        0.20        3798\n",
            "weighted avg              0.24        0.25        0.22        3798\n",
            "\n",
            "\n",
            "========================================\n",
            "Final RNN Model Accuracy from GitHub: 0.2480\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For LSTM"
      ],
      "metadata": {
        "id": "srmkJWZUv7W8"
      },
      "id": "srmkJWZUv7W8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model Hyperparameters\n",
        "# These must match the parameters used to train the saved model.\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# --- 2. Initialize a New, Untrained Model Instance ---\n",
        "print(\"Initializing a model structure...\")\n",
        "lstm_model_from_git = LSTMClassifier(VOCAB_SIZE, EMBED_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
        "\n",
        "# --- 3. Define the Raw URL for the Weights File ---\n",
        "lstm_weights_url = \"https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/lstm_model_weights.npz\"\n",
        "\n",
        "# --- Evaluation ---\n",
        "\n",
        "def evaluate_and_report_lstm(model, X, y, class_names=None, batch_size=64):\n",
        "    \"\"\"\n",
        "    Evaluates the LSTM model in mini-batches, prints a full classification report,\n",
        "    and returns the final accuracy.\n",
        "    \"\"\"\n",
        "    num_samples = len(X)\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(f\"Evaluating on {num_samples} samples in batches of {batch_size}...\")\n",
        "    pbar = tqdm(range(num_batches), desc=\"LSTM Evaluation Progress\")\n",
        "\n",
        "    for i in pbar:\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        X_batch = X[start_idx:end_idx]\n",
        "\n",
        "        # Check if the LSTM's forward pass uses a 'training' flag.\n",
        "        # Adjust if necessary based on your specific LSTMClassifier implementation.\n",
        "        # Assuming it does for consistency with the corrected RNN.\n",
        "        logits = model.forward(X_batch)\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "\n",
        "    # --- Generate the Detailed Report ---\n",
        "    print(\"\\n--- Classification Report for LSTM from GitHub ---\")\n",
        "    classification_report_from_scratch(y, all_predictions, class_names=class_names)\n",
        "\n",
        "    # Calculate and return the final accuracy\n",
        "    accuracy = np.mean(all_predictions == y)\n",
        "    return accuracy\n",
        "\n",
        "# --- 4. Load the Weights from the URL ---\n",
        "try:\n",
        "    print(\"Attempting to load LSTM weights from URL...\")\n",
        "    load_weights_from_url(lstm_model_from_git, lstm_weights_url)\n",
        "    print(\"LSTM weights successfully loaded.\")\n",
        "\n",
        "    # --- 5. Evaluate the Model's Performance ---\n",
        "\n",
        "    # Define class names for the report\n",
        "    class_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
        "\n",
        "    # Call the new function to get the report and accuracy\n",
        "    test_accuracy = evaluate_and_report_lstm(\n",
        "        lstm_model_from_git,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        class_names=class_labels\n",
        "    )\n",
        "\n",
        "    # --- 6. Show the Final Accuracy ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Final LSTM Model Accuracy from GitHub: {test_accuracy:.4f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n An error occurred: {e}\")\n",
        "    print(\"Please ensure the URL is correct and the file is accessible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592,
          "referenced_widgets": [
            "690925cd571a4469bac4c540a7d72b74",
            "56d915747ba0469e8526c988aa1f1048",
            "36d02a2ac55141178748dbb218cf3b9e",
            "0badbe434fd84c48bf7fe177b8468ef9",
            "5d1e0343feae4e6f9eb21fb6004d6893",
            "dc2e4b5e1ed5411d880457f68912339e",
            "887e8c43dd5449a1a4e7ba31b3acb28c",
            "24fd201b44c4421b9bee49062e7e611e",
            "edee2602745740b28919f97dcde2f8a9",
            "b2c3b4932e714160b2099a0e98d4e6da",
            "fdcb4547f4a44110811002436d2a190a"
          ]
        },
        "id": "2ADmP-1O1yT5",
        "outputId": "623b9544-120a-4736-8074-d059460eb32f"
      },
      "id": "2ADmP-1O1yT5",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing a model structure...\n",
            "Attempting to load LSTM weights from URL...\n",
            "Downloading weights from https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/lstm_model_weights.npz...\n",
            "Downloaded file contains the following keys: ['layer_0_W', 'layer_1_W_x', 'layer_1_W_h', 'layer_1_b', 'layer_2_W', 'layer_2_b']\n",
            "\n",
            "--- Attempting to match and load weights into model layers ---\n",
            " Successfully loaded layer_0_W\n",
            " Successfully loaded layer_1_W_x\n",
            " Successfully loaded layer_1_W_h\n",
            " Successfully loaded layer_1_b\n",
            " Successfully loaded layer_2_W\n",
            " Successfully loaded layer_2_b\n",
            "LSTM weights successfully loaded.\n",
            "Evaluating on 3798 samples in batches of 64...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LSTM Evaluation Progress:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "690925cd571a4469bac4c540a7d72b74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classification Report for LSTM from GitHub ---\n",
            "                     precision      recall    f1-score     support\n",
            "\n",
            "Extremely Negative        0.73        0.66        0.69         592\n",
            "Negative                  0.66        0.67        0.67        1041\n",
            "Neutral                   0.82        0.77        0.79         619\n",
            "Positive                  0.66        0.72        0.69         947\n",
            "Extremely Positive        0.76        0.75        0.76         599\n",
            "\n",
            "accuracy                                          0.71        3798\n",
            "micro avg                 0.71        0.71        0.71        3798\n",
            "macro avg                 0.73        0.71        0.72        3798\n",
            "weighted avg              0.71        0.71        0.71        3798\n",
            "\n",
            "\n",
            "========================================\n",
            "Final LSTM Model Accuracy from GitHub: 0.7098\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Transformer"
      ],
      "metadata": {
        "id": "Y4jChMl4wlLJ"
      },
      "id": "Y4jChMl4wlLJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import io\n",
        "\n",
        "def load_weights_from_url(model, url):\n",
        "    \"\"\"\n",
        "    Downloads and loads weights, matching the original simple saving function's keys.\n",
        "    \"\"\"\n",
        "    print(f\"Downloading weights from {url}...\")\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Will raise an error if download fails\n",
        "\n",
        "    # Load the weights from the downloaded content into memory\n",
        "    weights_from_file = np.load(io.BytesIO(response.content))\n",
        "    print(\"Downloaded file contains the following keys:\", list(weights_from_file.keys()))\n",
        "\n",
        "    print(\"\\n--- Attempting to match and load weights into model layers ---\")\n",
        "\n",
        "    # This loop MUST perfectly mirror your original save_weights function\n",
        "    # Iterate through the model's main layers with an index (i)\n",
        "    for i, layer in enumerate(model.layers):\n",
        "\n",
        "        # Iterate through the parameters within that layer\n",
        "        # For TransformerEncoderBlock, this correctly calls the @property\n",
        "        for key, param_obj in layer.params.items():\n",
        "\n",
        "            # Reconstruct the exact key name that was saved in the file\n",
        "            param_key = f'layer_{i}_{key}'\n",
        "\n",
        "            # Check if this reconstructed key exists in the loaded file\n",
        "            if param_key in weights_from_file:\n",
        "                # Sanity check: ensure the shapes match\n",
        "                assert param_obj.shape == weights_from_file[param_key].shape, \\\n",
        "                    f\"Shape mismatch for '{param_key}': Model expects {param_obj.shape}, file has {weights_from_file[param_key].shape}\"\n",
        "\n",
        "                # Assign the loaded weights to the model's parameter object\n",
        "                param_obj[:] = weights_from_file[param_key]\n",
        "                print(f\" Successfully loaded {param_key}\")\n",
        "            else:\n",
        "                print(f\" WARNING: Weight key '{param_key}' not found in the downloaded file.\")"
      ],
      "metadata": {
        "id": "hCbIFFQQ_2mp"
      },
      "id": "hCbIFFQQ_2mp",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# --- 1. Define Model Hyperparameters ---\n",
        "# These must match the parameters used to train the saved model.\n",
        "MAX_SEQ_LEN = 50\n",
        "VOCAB_SIZE = len(vocab)\n",
        "EMBED_DIM = 100\n",
        "NUM_HEADS = 5\n",
        "FFN_DIM = 400\n",
        "NUM_LAYERS = 4\n",
        "NUM_CLASSES = 5\n",
        "DROPOUT_P = 0.1\n",
        "\n",
        "# --- 2. Initialize a New, Untrained Model Instance ---\n",
        "print(\"Initializing a new model structure...\")\n",
        "transformer_model_from_git = TransformerClassifier(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    max_seq_len=MAX_SEQ_LEN,\n",
        "    embed_dim=EMBED_DIM,\n",
        "    num_heads=NUM_HEADS,\n",
        "    ffn_dim=FFN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    dropout_p=DROPOUT_P\n",
        ")\n",
        "\n",
        "# --- 3. Define the Raw URL for the Weights File ---\n",
        "transformer_weights_url = \"https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/transformer_model_weights.npz\"\n",
        "\n",
        "# --- 4. Define the Batched Evaluation and Reporting Function ---\n",
        "def evaluate_and_report_transformer(model, X, y, class_names=None, batch_size=64):\n",
        "    \"\"\"\n",
        "    Evaluates the Transformer model in mini-batches, prints a full classification report,\n",
        "    and returns the final accuracy.\n",
        "    \"\"\"\n",
        "    num_samples = len(X)\n",
        "    num_batches = (num_samples + batch_size - 1) // batch_size\n",
        "\n",
        "    all_predictions = []\n",
        "\n",
        "    print(f\"Evaluating on {num_samples} samples in batches of {batch_size}...\")\n",
        "    pbar = tqdm(range(num_batches), desc=\"Transformer Evaluation Progress\")\n",
        "\n",
        "    for i in pbar:\n",
        "        start_idx = i * batch_size\n",
        "        end_idx = start_idx + batch_size\n",
        "        X_batch = X[start_idx:end_idx]\n",
        "\n",
        "        logits = model.forward(X_batch, training=False)\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        all_predictions.extend(predictions.tolist())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "\n",
        "    # --- Generate the Detailed Report ---\n",
        "    print(\"\\n--- Classification Report for Transformer from GitHub ---\")\n",
        "    classification_report_from_scratch(y, all_predictions, class_names=class_names)\n",
        "\n",
        "    # Calculate and return the final accuracy\n",
        "    accuracy = np.mean(all_predictions == y)\n",
        "    return accuracy\n",
        "\n",
        "# --- 5. Load Weights and Evaluate the Model ---\n",
        "try:\n",
        "    # --- Step 5a: Load the Weights ---\n",
        "    print(\"\\nAttempting to load Transformer weights from URL...\")\n",
        "    load_weights_from_url(transformer_model_from_git, transformer_weights_url)\n",
        "    print(\"Transformer weights successfully loaded.\")\n",
        "\n",
        "    # --- Step 5b: Evaluate the Model's Performance ---\n",
        "\n",
        "    # Define class names for the report\n",
        "    class_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
        "\n",
        "    # Call the new function to get the report and accuracy\n",
        "    test_accuracy = evaluate_and_report_transformer(\n",
        "        transformer_model_from_git,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        class_names=class_labels,\n",
        "        batch_size=64\n",
        "    )\n",
        "\n",
        "    # --- Step 5c: Show the Final Accuracy ---\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Final Transformer Model Accuracy from GitHub: {test_accuracy:.4f}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred: {e}\")\n",
        "    print(\"Please ensure the URL is correct and the weights file is accessible.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8395a1a5efeb4c67bc905c4931ce6b32",
            "8044b0ddeca4449c94eb61c36bdf695c",
            "ff49b9f89aba49c09e34d0304930a48c",
            "8a1afab01f0141ab8f9a9319d21d0f0d",
            "b6e129be1f554da4a66d5d62d9261651",
            "d9a4f1657b544bad8a62abb69a68613d",
            "4f5dd3934b6d410b96626ded0ad6d28f",
            "bc0f71a21fe7425bbfabc7c794ca0881",
            "59683a99f3e44f3fb1b73087b0c9f2ce",
            "de027816ffe9455599324207d0179e71",
            "12d59fd877ed4a55908361e3ffd8f812"
          ]
        },
        "id": "b5ZFJ1oT-rEF",
        "outputId": "cf8eddf0-f37e-459e-e8e6-03ce063edc70"
      },
      "id": "b5ZFJ1oT-rEF",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing a new model structure...\n",
            "\n",
            "Attempting to load Transformer weights from URL...\n",
            "Downloading weights from https://raw.githubusercontent.com/anirudha22-stack/nlp_assignment_models/main/transformer_model_weights.npz...\n",
            "Downloaded file contains the following keys: ['layer_0_W', 'layer_3_MultiHeadAttention_0_W_qkv', 'layer_3_MultiHeadAttention_0_W_o', 'layer_3_LayerNormalization_1_gamma', 'layer_3_LayerNormalization_1_beta', 'layer_3_PositionwiseFeedForward_2_W_1', 'layer_3_PositionwiseFeedForward_2_b_1', 'layer_3_PositionwiseFeedForward_2_W_2', 'layer_3_PositionwiseFeedForward_2_b_2', 'layer_3_LayerNormalization_3_gamma', 'layer_3_LayerNormalization_3_beta', 'layer_4_MultiHeadAttention_0_W_qkv', 'layer_4_MultiHeadAttention_0_W_o', 'layer_4_LayerNormalization_1_gamma', 'layer_4_LayerNormalization_1_beta', 'layer_4_PositionwiseFeedForward_2_W_1', 'layer_4_PositionwiseFeedForward_2_b_1', 'layer_4_PositionwiseFeedForward_2_W_2', 'layer_4_PositionwiseFeedForward_2_b_2', 'layer_4_LayerNormalization_3_gamma', 'layer_4_LayerNormalization_3_beta', 'layer_5_MultiHeadAttention_0_W_qkv', 'layer_5_MultiHeadAttention_0_W_o', 'layer_5_LayerNormalization_1_gamma', 'layer_5_LayerNormalization_1_beta', 'layer_5_PositionwiseFeedForward_2_W_1', 'layer_5_PositionwiseFeedForward_2_b_1', 'layer_5_PositionwiseFeedForward_2_W_2', 'layer_5_PositionwiseFeedForward_2_b_2', 'layer_5_LayerNormalization_3_gamma', 'layer_5_LayerNormalization_3_beta', 'layer_6_MultiHeadAttention_0_W_qkv', 'layer_6_MultiHeadAttention_0_W_o', 'layer_6_LayerNormalization_1_gamma', 'layer_6_LayerNormalization_1_beta', 'layer_6_PositionwiseFeedForward_2_W_1', 'layer_6_PositionwiseFeedForward_2_b_1', 'layer_6_PositionwiseFeedForward_2_W_2', 'layer_6_PositionwiseFeedForward_2_b_2', 'layer_6_LayerNormalization_3_gamma', 'layer_6_LayerNormalization_3_beta', 'layer_8_W', 'layer_8_b']\n",
            "\n",
            "--- Attempting to match and load weights into model layers ---\n",
            " Successfully loaded layer_0_W\n",
            " Successfully loaded layer_3_MultiHeadAttention_0_W_qkv\n",
            " Successfully loaded layer_3_MultiHeadAttention_0_W_o\n",
            " Successfully loaded layer_3_LayerNormalization_1_gamma\n",
            " Successfully loaded layer_3_LayerNormalization_1_beta\n",
            " Successfully loaded layer_3_PositionwiseFeedForward_2_W_1\n",
            " Successfully loaded layer_3_PositionwiseFeedForward_2_b_1\n",
            " Successfully loaded layer_3_PositionwiseFeedForward_2_W_2\n",
            " Successfully loaded layer_3_PositionwiseFeedForward_2_b_2\n",
            " Successfully loaded layer_3_LayerNormalization_3_gamma\n",
            " Successfully loaded layer_3_LayerNormalization_3_beta\n",
            " Successfully loaded layer_4_MultiHeadAttention_0_W_qkv\n",
            " Successfully loaded layer_4_MultiHeadAttention_0_W_o\n",
            " Successfully loaded layer_4_LayerNormalization_1_gamma\n",
            " Successfully loaded layer_4_LayerNormalization_1_beta\n",
            " Successfully loaded layer_4_PositionwiseFeedForward_2_W_1\n",
            " Successfully loaded layer_4_PositionwiseFeedForward_2_b_1\n",
            " Successfully loaded layer_4_PositionwiseFeedForward_2_W_2\n",
            " Successfully loaded layer_4_PositionwiseFeedForward_2_b_2\n",
            " Successfully loaded layer_4_LayerNormalization_3_gamma\n",
            " Successfully loaded layer_4_LayerNormalization_3_beta\n",
            " Successfully loaded layer_5_MultiHeadAttention_0_W_qkv\n",
            " Successfully loaded layer_5_MultiHeadAttention_0_W_o\n",
            " Successfully loaded layer_5_LayerNormalization_1_gamma\n",
            " Successfully loaded layer_5_LayerNormalization_1_beta\n",
            " Successfully loaded layer_5_PositionwiseFeedForward_2_W_1\n",
            " Successfully loaded layer_5_PositionwiseFeedForward_2_b_1\n",
            " Successfully loaded layer_5_PositionwiseFeedForward_2_W_2\n",
            " Successfully loaded layer_5_PositionwiseFeedForward_2_b_2\n",
            " Successfully loaded layer_5_LayerNormalization_3_gamma\n",
            " Successfully loaded layer_5_LayerNormalization_3_beta\n",
            " Successfully loaded layer_6_MultiHeadAttention_0_W_qkv\n",
            " Successfully loaded layer_6_MultiHeadAttention_0_W_o\n",
            " Successfully loaded layer_6_LayerNormalization_1_gamma\n",
            " Successfully loaded layer_6_LayerNormalization_1_beta\n",
            " Successfully loaded layer_6_PositionwiseFeedForward_2_W_1\n",
            " Successfully loaded layer_6_PositionwiseFeedForward_2_b_1\n",
            " Successfully loaded layer_6_PositionwiseFeedForward_2_W_2\n",
            " Successfully loaded layer_6_PositionwiseFeedForward_2_b_2\n",
            " Successfully loaded layer_6_LayerNormalization_3_gamma\n",
            " Successfully loaded layer_6_LayerNormalization_3_beta\n",
            " Successfully loaded layer_8_W\n",
            " Successfully loaded layer_8_b\n",
            "Transformer weights successfully loaded.\n",
            "Evaluating on 3798 samples in batches of 64...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Transformer Evaluation Progress:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8395a1a5efeb4c67bc905c4931ce6b32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Classification Report for Transformer from GitHub ---\n",
            "                     precision      recall    f1-score     support\n",
            "\n",
            "Extremely Negative        0.67        0.78        0.72         592\n",
            "Negative                  0.67        0.67        0.67        1041\n",
            "Neutral                   0.86        0.78        0.82         619\n",
            "Positive                  0.73        0.65        0.69         947\n",
            "Extremely Positive        0.74        0.82        0.78         599\n",
            "\n",
            "accuracy                                          0.72        3798\n",
            "micro avg                 0.72        0.72        0.72        3798\n",
            "macro avg                 0.73        0.74        0.73        3798\n",
            "weighted avg              0.73        0.72        0.72        3798\n",
            "\n",
            "\n",
            "========================================\n",
            "Final Transformer Model Accuracy from GitHub: 0.7227\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OYhkygwsDxOX"
      },
      "id": "OYhkygwsDxOX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc105a014c36445f879d644a7bf581f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59b604b7990344fd8fe51e2cf69f762d",
              "IPY_MODEL_879fb89c22e74cf1a842d2c9cee9fc31",
              "IPY_MODEL_8839ceb84be14d959a548e3165657c29"
            ],
            "layout": "IPY_MODEL_31c301ed0dd64cdd920b0c7b1d87b338"
          }
        },
        "59b604b7990344fd8fe51e2cf69f762d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7820741132d742b28d9642047aa6689c",
            "placeholder": "​",
            "style": "IPY_MODEL_f02bd68531684e918b0365e2c5fefacf",
            "value": "RNN Evaluation Progress: 100%"
          }
        },
        "879fb89c22e74cf1a842d2c9cee9fc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7776cb87394422a45d60c0a043124b",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d0b1b688db540d292e552afda837186",
            "value": 60
          }
        },
        "8839ceb84be14d959a548e3165657c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2530b22b0c5b463db45d90ea5c8448cd",
            "placeholder": "​",
            "style": "IPY_MODEL_53aaa59cd2774457953c8e9e06200d89",
            "value": " 60/60 [00:07&lt;00:00,  3.81it/s]"
          }
        },
        "31c301ed0dd64cdd920b0c7b1d87b338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7820741132d742b28d9642047aa6689c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f02bd68531684e918b0365e2c5fefacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b7776cb87394422a45d60c0a043124b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0b1b688db540d292e552afda837186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2530b22b0c5b463db45d90ea5c8448cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53aaa59cd2774457953c8e9e06200d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "690925cd571a4469bac4c540a7d72b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56d915747ba0469e8526c988aa1f1048",
              "IPY_MODEL_36d02a2ac55141178748dbb218cf3b9e",
              "IPY_MODEL_0badbe434fd84c48bf7fe177b8468ef9"
            ],
            "layout": "IPY_MODEL_5d1e0343feae4e6f9eb21fb6004d6893"
          }
        },
        "56d915747ba0469e8526c988aa1f1048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2e4b5e1ed5411d880457f68912339e",
            "placeholder": "​",
            "style": "IPY_MODEL_887e8c43dd5449a1a4e7ba31b3acb28c",
            "value": "LSTM Evaluation Progress: 100%"
          }
        },
        "36d02a2ac55141178748dbb218cf3b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24fd201b44c4421b9bee49062e7e611e",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_edee2602745740b28919f97dcde2f8a9",
            "value": 60
          }
        },
        "0badbe434fd84c48bf7fe177b8468ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c3b4932e714160b2099a0e98d4e6da",
            "placeholder": "​",
            "style": "IPY_MODEL_fdcb4547f4a44110811002436d2a190a",
            "value": " 60/60 [00:11&lt;00:00,  6.98it/s]"
          }
        },
        "5d1e0343feae4e6f9eb21fb6004d6893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc2e4b5e1ed5411d880457f68912339e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887e8c43dd5449a1a4e7ba31b3acb28c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24fd201b44c4421b9bee49062e7e611e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edee2602745740b28919f97dcde2f8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2c3b4932e714160b2099a0e98d4e6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcb4547f4a44110811002436d2a190a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8395a1a5efeb4c67bc905c4931ce6b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8044b0ddeca4449c94eb61c36bdf695c",
              "IPY_MODEL_ff49b9f89aba49c09e34d0304930a48c",
              "IPY_MODEL_8a1afab01f0141ab8f9a9319d21d0f0d"
            ],
            "layout": "IPY_MODEL_b6e129be1f554da4a66d5d62d9261651"
          }
        },
        "8044b0ddeca4449c94eb61c36bdf695c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a4f1657b544bad8a62abb69a68613d",
            "placeholder": "​",
            "style": "IPY_MODEL_4f5dd3934b6d410b96626ded0ad6d28f",
            "value": "Transformer Evaluation Progress: 100%"
          }
        },
        "ff49b9f89aba49c09e34d0304930a48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc0f71a21fe7425bbfabc7c794ca0881",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59683a99f3e44f3fb1b73087b0c9f2ce",
            "value": 60
          }
        },
        "8a1afab01f0141ab8f9a9319d21d0f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de027816ffe9455599324207d0179e71",
            "placeholder": "​",
            "style": "IPY_MODEL_12d59fd877ed4a55908361e3ffd8f812",
            "value": " 60/60 [00:27&lt;00:00,  3.42it/s]"
          }
        },
        "b6e129be1f554da4a66d5d62d9261651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a4f1657b544bad8a62abb69a68613d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5dd3934b6d410b96626ded0ad6d28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc0f71a21fe7425bbfabc7c794ca0881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59683a99f3e44f3fb1b73087b0c9f2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de027816ffe9455599324207d0179e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d59fd877ed4a55908361e3ffd8f812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}